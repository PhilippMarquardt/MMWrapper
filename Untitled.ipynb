{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4923b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: C:\\Users\\philmarq\\source\\repos\\MMWrapperRepo\\firstapitest\\best_coco_bbox_mAP_epoch_25.pth\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: panoptic_head.pixel_decoder.input_convs.0.conv.weight, panoptic_head.pixel_decoder.input_convs.0.conv.bias, panoptic_head.pixel_decoder.input_convs.0.gn.weight, panoptic_head.pixel_decoder.input_convs.0.gn.bias, panoptic_head.pixel_decoder.input_convs.1.conv.weight, panoptic_head.pixel_decoder.input_convs.1.conv.bias, panoptic_head.pixel_decoder.input_convs.1.gn.weight, panoptic_head.pixel_decoder.input_convs.1.gn.bias, panoptic_head.pixel_decoder.input_convs.2.conv.weight, panoptic_head.pixel_decoder.input_convs.2.conv.bias, panoptic_head.pixel_decoder.input_convs.2.gn.weight, panoptic_head.pixel_decoder.input_convs.2.gn.bias, panoptic_head.pixel_decoder.encoder.layers.0.self_attn.sampling_offsets.weight, panoptic_head.pixel_decoder.encoder.layers.0.self_attn.sampling_offsets.bias, panoptic_head.pixel_decoder.encoder.layers.0.self_attn.attention_weights.weight, panoptic_head.pixel_decoder.encoder.layers.0.self_attn.attention_weights.bias, panoptic_head.pixel_decoder.encoder.layers.0.self_attn.value_proj.weight, panoptic_head.pixel_decoder.encoder.layers.0.self_attn.value_proj.bias, panoptic_head.pixel_decoder.encoder.layers.0.self_attn.output_proj.weight, panoptic_head.pixel_decoder.encoder.layers.0.self_attn.output_proj.bias, panoptic_head.pixel_decoder.encoder.layers.0.ffn.layers.0.0.weight, panoptic_head.pixel_decoder.encoder.layers.0.ffn.layers.0.0.bias, panoptic_head.pixel_decoder.encoder.layers.0.ffn.layers.1.weight, panoptic_head.pixel_decoder.encoder.layers.0.ffn.layers.1.bias, panoptic_head.pixel_decoder.encoder.layers.0.norms.0.weight, panoptic_head.pixel_decoder.encoder.layers.0.norms.0.bias, panoptic_head.pixel_decoder.encoder.layers.0.norms.1.weight, panoptic_head.pixel_decoder.encoder.layers.0.norms.1.bias, panoptic_head.pixel_decoder.encoder.layers.1.self_attn.sampling_offsets.weight, panoptic_head.pixel_decoder.encoder.layers.1.self_attn.sampling_offsets.bias, panoptic_head.pixel_decoder.encoder.layers.1.self_attn.attention_weights.weight, panoptic_head.pixel_decoder.encoder.layers.1.self_attn.attention_weights.bias, panoptic_head.pixel_decoder.encoder.layers.1.self_attn.value_proj.weight, panoptic_head.pixel_decoder.encoder.layers.1.self_attn.value_proj.bias, panoptic_head.pixel_decoder.encoder.layers.1.self_attn.output_proj.weight, panoptic_head.pixel_decoder.encoder.layers.1.self_attn.output_proj.bias, panoptic_head.pixel_decoder.encoder.layers.1.ffn.layers.0.0.weight, panoptic_head.pixel_decoder.encoder.layers.1.ffn.layers.0.0.bias, panoptic_head.pixel_decoder.encoder.layers.1.ffn.layers.1.weight, panoptic_head.pixel_decoder.encoder.layers.1.ffn.layers.1.bias, panoptic_head.pixel_decoder.encoder.layers.1.norms.0.weight, panoptic_head.pixel_decoder.encoder.layers.1.norms.0.bias, panoptic_head.pixel_decoder.encoder.layers.1.norms.1.weight, panoptic_head.pixel_decoder.encoder.layers.1.norms.1.bias, panoptic_head.pixel_decoder.encoder.layers.2.self_attn.sampling_offsets.weight, panoptic_head.pixel_decoder.encoder.layers.2.self_attn.sampling_offsets.bias, panoptic_head.pixel_decoder.encoder.layers.2.self_attn.attention_weights.weight, panoptic_head.pixel_decoder.encoder.layers.2.self_attn.attention_weights.bias, panoptic_head.pixel_decoder.encoder.layers.2.self_attn.value_proj.weight, panoptic_head.pixel_decoder.encoder.layers.2.self_attn.value_proj.bias, panoptic_head.pixel_decoder.encoder.layers.2.self_attn.output_proj.weight, panoptic_head.pixel_decoder.encoder.layers.2.self_attn.output_proj.bias, panoptic_head.pixel_decoder.encoder.layers.2.ffn.layers.0.0.weight, panoptic_head.pixel_decoder.encoder.layers.2.ffn.layers.0.0.bias, panoptic_head.pixel_decoder.encoder.layers.2.ffn.layers.1.weight, panoptic_head.pixel_decoder.encoder.layers.2.ffn.layers.1.bias, panoptic_head.pixel_decoder.encoder.layers.2.norms.0.weight, panoptic_head.pixel_decoder.encoder.layers.2.norms.0.bias, panoptic_head.pixel_decoder.encoder.layers.2.norms.1.weight, panoptic_head.pixel_decoder.encoder.layers.2.norms.1.bias, panoptic_head.pixel_decoder.encoder.layers.3.self_attn.sampling_offsets.weight, panoptic_head.pixel_decoder.encoder.layers.3.self_attn.sampling_offsets.bias, panoptic_head.pixel_decoder.encoder.layers.3.self_attn.attention_weights.weight, panoptic_head.pixel_decoder.encoder.layers.3.self_attn.attention_weights.bias, panoptic_head.pixel_decoder.encoder.layers.3.self_attn.value_proj.weight, panoptic_head.pixel_decoder.encoder.layers.3.self_attn.value_proj.bias, panoptic_head.pixel_decoder.encoder.layers.3.self_attn.output_proj.weight, panoptic_head.pixel_decoder.encoder.layers.3.self_attn.output_proj.bias, panoptic_head.pixel_decoder.encoder.layers.3.ffn.layers.0.0.weight, panoptic_head.pixel_decoder.encoder.layers.3.ffn.layers.0.0.bias, panoptic_head.pixel_decoder.encoder.layers.3.ffn.layers.1.weight, panoptic_head.pixel_decoder.encoder.layers.3.ffn.layers.1.bias, panoptic_head.pixel_decoder.encoder.layers.3.norms.0.weight, panoptic_head.pixel_decoder.encoder.layers.3.norms.0.bias, panoptic_head.pixel_decoder.encoder.layers.3.norms.1.weight, panoptic_head.pixel_decoder.encoder.layers.3.norms.1.bias, panoptic_head.pixel_decoder.encoder.layers.4.self_attn.sampling_offsets.weight, panoptic_head.pixel_decoder.encoder.layers.4.self_attn.sampling_offsets.bias, panoptic_head.pixel_decoder.encoder.layers.4.self_attn.attention_weights.weight, panoptic_head.pixel_decoder.encoder.layers.4.self_attn.attention_weights.bias, panoptic_head.pixel_decoder.encoder.layers.4.self_attn.value_proj.weight, panoptic_head.pixel_decoder.encoder.layers.4.self_attn.value_proj.bias, panoptic_head.pixel_decoder.encoder.layers.4.self_attn.output_proj.weight, panoptic_head.pixel_decoder.encoder.layers.4.self_attn.output_proj.bias, panoptic_head.pixel_decoder.encoder.layers.4.ffn.layers.0.0.weight, panoptic_head.pixel_decoder.encoder.layers.4.ffn.layers.0.0.bias, panoptic_head.pixel_decoder.encoder.layers.4.ffn.layers.1.weight, panoptic_head.pixel_decoder.encoder.layers.4.ffn.layers.1.bias, panoptic_head.pixel_decoder.encoder.layers.4.norms.0.weight, panoptic_head.pixel_decoder.encoder.layers.4.norms.0.bias, panoptic_head.pixel_decoder.encoder.layers.4.norms.1.weight, panoptic_head.pixel_decoder.encoder.layers.4.norms.1.bias, panoptic_head.pixel_decoder.encoder.layers.5.self_attn.sampling_offsets.weight, panoptic_head.pixel_decoder.encoder.layers.5.self_attn.sampling_offsets.bias, panoptic_head.pixel_decoder.encoder.layers.5.self_attn.attention_weights.weight, panoptic_head.pixel_decoder.encoder.layers.5.self_attn.attention_weights.bias, panoptic_head.pixel_decoder.encoder.layers.5.self_attn.value_proj.weight, panoptic_head.pixel_decoder.encoder.layers.5.self_attn.value_proj.bias, panoptic_head.pixel_decoder.encoder.layers.5.self_attn.output_proj.weight, panoptic_head.pixel_decoder.encoder.layers.5.self_attn.output_proj.bias, panoptic_head.pixel_decoder.encoder.layers.5.ffn.layers.0.0.weight, panoptic_head.pixel_decoder.encoder.layers.5.ffn.layers.0.0.bias, panoptic_head.pixel_decoder.encoder.layers.5.ffn.layers.1.weight, panoptic_head.pixel_decoder.encoder.layers.5.ffn.layers.1.bias, panoptic_head.pixel_decoder.encoder.layers.5.norms.0.weight, panoptic_head.pixel_decoder.encoder.layers.5.norms.0.bias, panoptic_head.pixel_decoder.encoder.layers.5.norms.1.weight, panoptic_head.pixel_decoder.encoder.layers.5.norms.1.bias, panoptic_head.pixel_decoder.level_encoding.weight, panoptic_head.pixel_decoder.lateral_convs.0.conv.weight, panoptic_head.pixel_decoder.lateral_convs.0.gn.weight, panoptic_head.pixel_decoder.lateral_convs.0.gn.bias, panoptic_head.pixel_decoder.output_convs.0.conv.weight, panoptic_head.pixel_decoder.output_convs.0.gn.weight, panoptic_head.pixel_decoder.output_convs.0.gn.bias, panoptic_head.pixel_decoder.mask_feature.weight, panoptic_head.pixel_decoder.mask_feature.bias, panoptic_head.transformer_decoder.layers.0.self_attn.attn.in_proj_weight, panoptic_head.transformer_decoder.layers.0.self_attn.attn.in_proj_bias, panoptic_head.transformer_decoder.layers.0.self_attn.attn.out_proj.weight, panoptic_head.transformer_decoder.layers.0.self_attn.attn.out_proj.bias, panoptic_head.transformer_decoder.layers.0.cross_attn.attn.in_proj_weight, panoptic_head.transformer_decoder.layers.0.cross_attn.attn.in_proj_bias, panoptic_head.transformer_decoder.layers.0.cross_attn.attn.out_proj.weight, panoptic_head.transformer_decoder.layers.0.cross_attn.attn.out_proj.bias, panoptic_head.transformer_decoder.layers.0.ffn.layers.0.0.weight, panoptic_head.transformer_decoder.layers.0.ffn.layers.0.0.bias, panoptic_head.transformer_decoder.layers.0.ffn.layers.1.weight, panoptic_head.transformer_decoder.layers.0.ffn.layers.1.bias, panoptic_head.transformer_decoder.layers.0.norms.0.weight, panoptic_head.transformer_decoder.layers.0.norms.0.bias, panoptic_head.transformer_decoder.layers.0.norms.1.weight, panoptic_head.transformer_decoder.layers.0.norms.1.bias, panoptic_head.transformer_decoder.layers.0.norms.2.weight, panoptic_head.transformer_decoder.layers.0.norms.2.bias, panoptic_head.transformer_decoder.layers.1.self_attn.attn.in_proj_weight, panoptic_head.transformer_decoder.layers.1.self_attn.attn.in_proj_bias, panoptic_head.transformer_decoder.layers.1.self_attn.attn.out_proj.weight, panoptic_head.transformer_decoder.layers.1.self_attn.attn.out_proj.bias, panoptic_head.transformer_decoder.layers.1.cross_attn.attn.in_proj_weight, panoptic_head.transformer_decoder.layers.1.cross_attn.attn.in_proj_bias, panoptic_head.transformer_decoder.layers.1.cross_attn.attn.out_proj.weight, panoptic_head.transformer_decoder.layers.1.cross_attn.attn.out_proj.bias, panoptic_head.transformer_decoder.layers.1.ffn.layers.0.0.weight, panoptic_head.transformer_decoder.layers.1.ffn.layers.0.0.bias, panoptic_head.transformer_decoder.layers.1.ffn.layers.1.weight, panoptic_head.transformer_decoder.layers.1.ffn.layers.1.bias, panoptic_head.transformer_decoder.layers.1.norms.0.weight, panoptic_head.transformer_decoder.layers.1.norms.0.bias, panoptic_head.transformer_decoder.layers.1.norms.1.weight, panoptic_head.transformer_decoder.layers.1.norms.1.bias, panoptic_head.transformer_decoder.layers.1.norms.2.weight, panoptic_head.transformer_decoder.layers.1.norms.2.bias, panoptic_head.transformer_decoder.layers.2.self_attn.attn.in_proj_weight, panoptic_head.transformer_decoder.layers.2.self_attn.attn.in_proj_bias, panoptic_head.transformer_decoder.layers.2.self_attn.attn.out_proj.weight, panoptic_head.transformer_decoder.layers.2.self_attn.attn.out_proj.bias, panoptic_head.transformer_decoder.layers.2.cross_attn.attn.in_proj_weight, panoptic_head.transformer_decoder.layers.2.cross_attn.attn.in_proj_bias, panoptic_head.transformer_decoder.layers.2.cross_attn.attn.out_proj.weight, panoptic_head.transformer_decoder.layers.2.cross_attn.attn.out_proj.bias, panoptic_head.transformer_decoder.layers.2.ffn.layers.0.0.weight, panoptic_head.transformer_decoder.layers.2.ffn.layers.0.0.bias, panoptic_head.transformer_decoder.layers.2.ffn.layers.1.weight, panoptic_head.transformer_decoder.layers.2.ffn.layers.1.bias, panoptic_head.transformer_decoder.layers.2.norms.0.weight, panoptic_head.transformer_decoder.layers.2.norms.0.bias, panoptic_head.transformer_decoder.layers.2.norms.1.weight, panoptic_head.transformer_decoder.layers.2.norms.1.bias, panoptic_head.transformer_decoder.layers.2.norms.2.weight, panoptic_head.transformer_decoder.layers.2.norms.2.bias, panoptic_head.transformer_decoder.layers.3.self_attn.attn.in_proj_weight, panoptic_head.transformer_decoder.layers.3.self_attn.attn.in_proj_bias, panoptic_head.transformer_decoder.layers.3.self_attn.attn.out_proj.weight, panoptic_head.transformer_decoder.layers.3.self_attn.attn.out_proj.bias, panoptic_head.transformer_decoder.layers.3.cross_attn.attn.in_proj_weight, panoptic_head.transformer_decoder.layers.3.cross_attn.attn.in_proj_bias, panoptic_head.transformer_decoder.layers.3.cross_attn.attn.out_proj.weight, panoptic_head.transformer_decoder.layers.3.cross_attn.attn.out_proj.bias, panoptic_head.transformer_decoder.layers.3.ffn.layers.0.0.weight, panoptic_head.transformer_decoder.layers.3.ffn.layers.0.0.bias, panoptic_head.transformer_decoder.layers.3.ffn.layers.1.weight, panoptic_head.transformer_decoder.layers.3.ffn.layers.1.bias, panoptic_head.transformer_decoder.layers.3.norms.0.weight, panoptic_head.transformer_decoder.layers.3.norms.0.bias, panoptic_head.transformer_decoder.layers.3.norms.1.weight, panoptic_head.transformer_decoder.layers.3.norms.1.bias, panoptic_head.transformer_decoder.layers.3.norms.2.weight, panoptic_head.transformer_decoder.layers.3.norms.2.bias, panoptic_head.transformer_decoder.layers.4.self_attn.attn.in_proj_weight, panoptic_head.transformer_decoder.layers.4.self_attn.attn.in_proj_bias, panoptic_head.transformer_decoder.layers.4.self_attn.attn.out_proj.weight, panoptic_head.transformer_decoder.layers.4.self_attn.attn.out_proj.bias, panoptic_head.transformer_decoder.layers.4.cross_attn.attn.in_proj_weight, panoptic_head.transformer_decoder.layers.4.cross_attn.attn.in_proj_bias, panoptic_head.transformer_decoder.layers.4.cross_attn.attn.out_proj.weight, panoptic_head.transformer_decoder.layers.4.cross_attn.attn.out_proj.bias, panoptic_head.transformer_decoder.layers.4.ffn.layers.0.0.weight, panoptic_head.transformer_decoder.layers.4.ffn.layers.0.0.bias, panoptic_head.transformer_decoder.layers.4.ffn.layers.1.weight, panoptic_head.transformer_decoder.layers.4.ffn.layers.1.bias, panoptic_head.transformer_decoder.layers.4.norms.0.weight, panoptic_head.transformer_decoder.layers.4.norms.0.bias, panoptic_head.transformer_decoder.layers.4.norms.1.weight, panoptic_head.transformer_decoder.layers.4.norms.1.bias, panoptic_head.transformer_decoder.layers.4.norms.2.weight, panoptic_head.transformer_decoder.layers.4.norms.2.bias, panoptic_head.transformer_decoder.layers.5.self_attn.attn.in_proj_weight, panoptic_head.transformer_decoder.layers.5.self_attn.attn.in_proj_bias, panoptic_head.transformer_decoder.layers.5.self_attn.attn.out_proj.weight, panoptic_head.transformer_decoder.layers.5.self_attn.attn.out_proj.bias, panoptic_head.transformer_decoder.layers.5.cross_attn.attn.in_proj_weight, panoptic_head.transformer_decoder.layers.5.cross_attn.attn.in_proj_bias, panoptic_head.transformer_decoder.layers.5.cross_attn.attn.out_proj.weight, panoptic_head.transformer_decoder.layers.5.cross_attn.attn.out_proj.bias, panoptic_head.transformer_decoder.layers.5.ffn.layers.0.0.weight, panoptic_head.transformer_decoder.layers.5.ffn.layers.0.0.bias, panoptic_head.transformer_decoder.layers.5.ffn.layers.1.weight, panoptic_head.transformer_decoder.layers.5.ffn.layers.1.bias, panoptic_head.transformer_decoder.layers.5.norms.0.weight, panoptic_head.transformer_decoder.layers.5.norms.0.bias, panoptic_head.transformer_decoder.layers.5.norms.1.weight, panoptic_head.transformer_decoder.layers.5.norms.1.bias, panoptic_head.transformer_decoder.layers.5.norms.2.weight, panoptic_head.transformer_decoder.layers.5.norms.2.bias, panoptic_head.transformer_decoder.layers.6.self_attn.attn.in_proj_weight, panoptic_head.transformer_decoder.layers.6.self_attn.attn.in_proj_bias, panoptic_head.transformer_decoder.layers.6.self_attn.attn.out_proj.weight, panoptic_head.transformer_decoder.layers.6.self_attn.attn.out_proj.bias, panoptic_head.transformer_decoder.layers.6.cross_attn.attn.in_proj_weight, panoptic_head.transformer_decoder.layers.6.cross_attn.attn.in_proj_bias, panoptic_head.transformer_decoder.layers.6.cross_attn.attn.out_proj.weight, panoptic_head.transformer_decoder.layers.6.cross_attn.attn.out_proj.bias, panoptic_head.transformer_decoder.layers.6.ffn.layers.0.0.weight, panoptic_head.transformer_decoder.layers.6.ffn.layers.0.0.bias, panoptic_head.transformer_decoder.layers.6.ffn.layers.1.weight, panoptic_head.transformer_decoder.layers.6.ffn.layers.1.bias, panoptic_head.transformer_decoder.layers.6.norms.0.weight, panoptic_head.transformer_decoder.layers.6.norms.0.bias, panoptic_head.transformer_decoder.layers.6.norms.1.weight, panoptic_head.transformer_decoder.layers.6.norms.1.bias, panoptic_head.transformer_decoder.layers.6.norms.2.weight, panoptic_head.transformer_decoder.layers.6.norms.2.bias, panoptic_head.transformer_decoder.layers.7.self_attn.attn.in_proj_weight, panoptic_head.transformer_decoder.layers.7.self_attn.attn.in_proj_bias, panoptic_head.transformer_decoder.layers.7.self_attn.attn.out_proj.weight, panoptic_head.transformer_decoder.layers.7.self_attn.attn.out_proj.bias, panoptic_head.transformer_decoder.layers.7.cross_attn.attn.in_proj_weight, panoptic_head.transformer_decoder.layers.7.cross_attn.attn.in_proj_bias, panoptic_head.transformer_decoder.layers.7.cross_attn.attn.out_proj.weight, panoptic_head.transformer_decoder.layers.7.cross_attn.attn.out_proj.bias, panoptic_head.transformer_decoder.layers.7.ffn.layers.0.0.weight, panoptic_head.transformer_decoder.layers.7.ffn.layers.0.0.bias, panoptic_head.transformer_decoder.layers.7.ffn.layers.1.weight, panoptic_head.transformer_decoder.layers.7.ffn.layers.1.bias, panoptic_head.transformer_decoder.layers.7.norms.0.weight, panoptic_head.transformer_decoder.layers.7.norms.0.bias, panoptic_head.transformer_decoder.layers.7.norms.1.weight, panoptic_head.transformer_decoder.layers.7.norms.1.bias, panoptic_head.transformer_decoder.layers.7.norms.2.weight, panoptic_head.transformer_decoder.layers.7.norms.2.bias, panoptic_head.transformer_decoder.layers.8.self_attn.attn.in_proj_weight, panoptic_head.transformer_decoder.layers.8.self_attn.attn.in_proj_bias, panoptic_head.transformer_decoder.layers.8.self_attn.attn.out_proj.weight, panoptic_head.transformer_decoder.layers.8.self_attn.attn.out_proj.bias, panoptic_head.transformer_decoder.layers.8.cross_attn.attn.in_proj_weight, panoptic_head.transformer_decoder.layers.8.cross_attn.attn.in_proj_bias, panoptic_head.transformer_decoder.layers.8.cross_attn.attn.out_proj.weight, panoptic_head.transformer_decoder.layers.8.cross_attn.attn.out_proj.bias, panoptic_head.transformer_decoder.layers.8.ffn.layers.0.0.weight, panoptic_head.transformer_decoder.layers.8.ffn.layers.0.0.bias, panoptic_head.transformer_decoder.layers.8.ffn.layers.1.weight, panoptic_head.transformer_decoder.layers.8.ffn.layers.1.bias, panoptic_head.transformer_decoder.layers.8.norms.0.weight, panoptic_head.transformer_decoder.layers.8.norms.0.bias, panoptic_head.transformer_decoder.layers.8.norms.1.weight, panoptic_head.transformer_decoder.layers.8.norms.1.bias, panoptic_head.transformer_decoder.layers.8.norms.2.weight, panoptic_head.transformer_decoder.layers.8.norms.2.bias, panoptic_head.transformer_decoder.post_norm.weight, panoptic_head.transformer_decoder.post_norm.bias, panoptic_head.query_embed.weight, panoptic_head.query_feat.weight, panoptic_head.level_embed.weight, panoptic_head.cls_embed.weight, panoptic_head.cls_embed.bias, panoptic_head.mask_embed.0.weight, panoptic_head.mask_embed.0.bias, panoptic_head.mask_embed.2.weight, panoptic_head.mask_embed.2.bias, panoptic_head.mask_embed.4.weight, panoptic_head.mask_embed.4.bias, backbone.patch_embed.projection.weight, backbone.patch_embed.projection.bias, backbone.patch_embed.norm.weight, backbone.patch_embed.norm.bias, backbone.stages.0.blocks.0.norm1.weight, backbone.stages.0.blocks.0.norm1.bias, backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table, backbone.stages.0.blocks.0.attn.w_msa.relative_position_index, backbone.stages.0.blocks.0.attn.w_msa.qkv.weight, backbone.stages.0.blocks.0.attn.w_msa.qkv.bias, backbone.stages.0.blocks.0.attn.w_msa.proj.weight, backbone.stages.0.blocks.0.attn.w_msa.proj.bias, backbone.stages.0.blocks.0.norm2.weight, backbone.stages.0.blocks.0.norm2.bias, backbone.stages.0.blocks.0.ffn.layers.0.0.weight, backbone.stages.0.blocks.0.ffn.layers.0.0.bias, backbone.stages.0.blocks.0.ffn.layers.1.weight, backbone.stages.0.blocks.0.ffn.layers.1.bias, backbone.stages.0.blocks.1.norm1.weight, backbone.stages.0.blocks.1.norm1.bias, backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table, backbone.stages.0.blocks.1.attn.w_msa.relative_position_index, backbone.stages.0.blocks.1.attn.w_msa.qkv.weight, backbone.stages.0.blocks.1.attn.w_msa.qkv.bias, backbone.stages.0.blocks.1.attn.w_msa.proj.weight, backbone.stages.0.blocks.1.attn.w_msa.proj.bias, backbone.stages.0.blocks.1.norm2.weight, backbone.stages.0.blocks.1.norm2.bias, backbone.stages.0.blocks.1.ffn.layers.0.0.weight, backbone.stages.0.blocks.1.ffn.layers.0.0.bias, backbone.stages.0.blocks.1.ffn.layers.1.weight, backbone.stages.0.blocks.1.ffn.layers.1.bias, backbone.stages.0.downsample.norm.weight, backbone.stages.0.downsample.norm.bias, backbone.stages.0.downsample.reduction.weight, backbone.stages.1.blocks.0.norm1.weight, backbone.stages.1.blocks.0.norm1.bias, backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table, backbone.stages.1.blocks.0.attn.w_msa.relative_position_index, backbone.stages.1.blocks.0.attn.w_msa.qkv.weight, backbone.stages.1.blocks.0.attn.w_msa.qkv.bias, backbone.stages.1.blocks.0.attn.w_msa.proj.weight, backbone.stages.1.blocks.0.attn.w_msa.proj.bias, backbone.stages.1.blocks.0.norm2.weight, backbone.stages.1.blocks.0.norm2.bias, backbone.stages.1.blocks.0.ffn.layers.0.0.weight, backbone.stages.1.blocks.0.ffn.layers.0.0.bias, backbone.stages.1.blocks.0.ffn.layers.1.weight, backbone.stages.1.blocks.0.ffn.layers.1.bias, backbone.stages.1.blocks.1.norm1.weight, backbone.stages.1.blocks.1.norm1.bias, backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table, backbone.stages.1.blocks.1.attn.w_msa.relative_position_index, backbone.stages.1.blocks.1.attn.w_msa.qkv.weight, backbone.stages.1.blocks.1.attn.w_msa.qkv.bias, backbone.stages.1.blocks.1.attn.w_msa.proj.weight, backbone.stages.1.blocks.1.attn.w_msa.proj.bias, backbone.stages.1.blocks.1.norm2.weight, backbone.stages.1.blocks.1.norm2.bias, backbone.stages.1.blocks.1.ffn.layers.0.0.weight, backbone.stages.1.blocks.1.ffn.layers.0.0.bias, backbone.stages.1.blocks.1.ffn.layers.1.weight, backbone.stages.1.blocks.1.ffn.layers.1.bias, backbone.stages.1.downsample.norm.weight, backbone.stages.1.downsample.norm.bias, backbone.stages.1.downsample.reduction.weight, backbone.stages.2.blocks.0.norm1.weight, backbone.stages.2.blocks.0.norm1.bias, backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.0.attn.w_msa.relative_position_index, backbone.stages.2.blocks.0.attn.w_msa.qkv.weight, backbone.stages.2.blocks.0.attn.w_msa.qkv.bias, backbone.stages.2.blocks.0.attn.w_msa.proj.weight, backbone.stages.2.blocks.0.attn.w_msa.proj.bias, backbone.stages.2.blocks.0.norm2.weight, backbone.stages.2.blocks.0.norm2.bias, backbone.stages.2.blocks.0.ffn.layers.0.0.weight, backbone.stages.2.blocks.0.ffn.layers.0.0.bias, backbone.stages.2.blocks.0.ffn.layers.1.weight, backbone.stages.2.blocks.0.ffn.layers.1.bias, backbone.stages.2.blocks.1.norm1.weight, backbone.stages.2.blocks.1.norm1.bias, backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.1.attn.w_msa.relative_position_index, backbone.stages.2.blocks.1.attn.w_msa.qkv.weight, backbone.stages.2.blocks.1.attn.w_msa.qkv.bias, backbone.stages.2.blocks.1.attn.w_msa.proj.weight, backbone.stages.2.blocks.1.attn.w_msa.proj.bias, backbone.stages.2.blocks.1.norm2.weight, backbone.stages.2.blocks.1.norm2.bias, backbone.stages.2.blocks.1.ffn.layers.0.0.weight, backbone.stages.2.blocks.1.ffn.layers.0.0.bias, backbone.stages.2.blocks.1.ffn.layers.1.weight, backbone.stages.2.blocks.1.ffn.layers.1.bias, backbone.stages.2.blocks.2.norm1.weight, backbone.stages.2.blocks.2.norm1.bias, backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.2.attn.w_msa.relative_position_index, backbone.stages.2.blocks.2.attn.w_msa.qkv.weight, backbone.stages.2.blocks.2.attn.w_msa.qkv.bias, backbone.stages.2.blocks.2.attn.w_msa.proj.weight, backbone.stages.2.blocks.2.attn.w_msa.proj.bias, backbone.stages.2.blocks.2.norm2.weight, backbone.stages.2.blocks.2.norm2.bias, backbone.stages.2.blocks.2.ffn.layers.0.0.weight, backbone.stages.2.blocks.2.ffn.layers.0.0.bias, backbone.stages.2.blocks.2.ffn.layers.1.weight, backbone.stages.2.blocks.2.ffn.layers.1.bias, backbone.stages.2.blocks.3.norm1.weight, backbone.stages.2.blocks.3.norm1.bias, backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.3.attn.w_msa.relative_position_index, backbone.stages.2.blocks.3.attn.w_msa.qkv.weight, backbone.stages.2.blocks.3.attn.w_msa.qkv.bias, backbone.stages.2.blocks.3.attn.w_msa.proj.weight, backbone.stages.2.blocks.3.attn.w_msa.proj.bias, backbone.stages.2.blocks.3.norm2.weight, backbone.stages.2.blocks.3.norm2.bias, backbone.stages.2.blocks.3.ffn.layers.0.0.weight, backbone.stages.2.blocks.3.ffn.layers.0.0.bias, backbone.stages.2.blocks.3.ffn.layers.1.weight, backbone.stages.2.blocks.3.ffn.layers.1.bias, backbone.stages.2.blocks.4.norm1.weight, backbone.stages.2.blocks.4.norm1.bias, backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.4.attn.w_msa.relative_position_index, backbone.stages.2.blocks.4.attn.w_msa.qkv.weight, backbone.stages.2.blocks.4.attn.w_msa.qkv.bias, backbone.stages.2.blocks.4.attn.w_msa.proj.weight, backbone.stages.2.blocks.4.attn.w_msa.proj.bias, backbone.stages.2.blocks.4.norm2.weight, backbone.stages.2.blocks.4.norm2.bias, backbone.stages.2.blocks.4.ffn.layers.0.0.weight, backbone.stages.2.blocks.4.ffn.layers.0.0.bias, backbone.stages.2.blocks.4.ffn.layers.1.weight, backbone.stages.2.blocks.4.ffn.layers.1.bias, backbone.stages.2.blocks.5.norm1.weight, backbone.stages.2.blocks.5.norm1.bias, backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.5.attn.w_msa.relative_position_index, backbone.stages.2.blocks.5.attn.w_msa.qkv.weight, backbone.stages.2.blocks.5.attn.w_msa.qkv.bias, backbone.stages.2.blocks.5.attn.w_msa.proj.weight, backbone.stages.2.blocks.5.attn.w_msa.proj.bias, backbone.stages.2.blocks.5.norm2.weight, backbone.stages.2.blocks.5.norm2.bias, backbone.stages.2.blocks.5.ffn.layers.0.0.weight, backbone.stages.2.blocks.5.ffn.layers.0.0.bias, backbone.stages.2.blocks.5.ffn.layers.1.weight, backbone.stages.2.blocks.5.ffn.layers.1.bias, backbone.stages.2.blocks.6.norm1.weight, backbone.stages.2.blocks.6.norm1.bias, backbone.stages.2.blocks.6.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.6.attn.w_msa.relative_position_index, backbone.stages.2.blocks.6.attn.w_msa.qkv.weight, backbone.stages.2.blocks.6.attn.w_msa.qkv.bias, backbone.stages.2.blocks.6.attn.w_msa.proj.weight, backbone.stages.2.blocks.6.attn.w_msa.proj.bias, backbone.stages.2.blocks.6.norm2.weight, backbone.stages.2.blocks.6.norm2.bias, backbone.stages.2.blocks.6.ffn.layers.0.0.weight, backbone.stages.2.blocks.6.ffn.layers.0.0.bias, backbone.stages.2.blocks.6.ffn.layers.1.weight, backbone.stages.2.blocks.6.ffn.layers.1.bias, backbone.stages.2.blocks.7.norm1.weight, backbone.stages.2.blocks.7.norm1.bias, backbone.stages.2.blocks.7.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.7.attn.w_msa.relative_position_index, backbone.stages.2.blocks.7.attn.w_msa.qkv.weight, backbone.stages.2.blocks.7.attn.w_msa.qkv.bias, backbone.stages.2.blocks.7.attn.w_msa.proj.weight, backbone.stages.2.blocks.7.attn.w_msa.proj.bias, backbone.stages.2.blocks.7.norm2.weight, backbone.stages.2.blocks.7.norm2.bias, backbone.stages.2.blocks.7.ffn.layers.0.0.weight, backbone.stages.2.blocks.7.ffn.layers.0.0.bias, backbone.stages.2.blocks.7.ffn.layers.1.weight, backbone.stages.2.blocks.7.ffn.layers.1.bias, backbone.stages.2.blocks.8.norm1.weight, backbone.stages.2.blocks.8.norm1.bias, backbone.stages.2.blocks.8.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.8.attn.w_msa.relative_position_index, backbone.stages.2.blocks.8.attn.w_msa.qkv.weight, backbone.stages.2.blocks.8.attn.w_msa.qkv.bias, backbone.stages.2.blocks.8.attn.w_msa.proj.weight, backbone.stages.2.blocks.8.attn.w_msa.proj.bias, backbone.stages.2.blocks.8.norm2.weight, backbone.stages.2.blocks.8.norm2.bias, backbone.stages.2.blocks.8.ffn.layers.0.0.weight, backbone.stages.2.blocks.8.ffn.layers.0.0.bias, backbone.stages.2.blocks.8.ffn.layers.1.weight, backbone.stages.2.blocks.8.ffn.layers.1.bias, backbone.stages.2.blocks.9.norm1.weight, backbone.stages.2.blocks.9.norm1.bias, backbone.stages.2.blocks.9.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.9.attn.w_msa.relative_position_index, backbone.stages.2.blocks.9.attn.w_msa.qkv.weight, backbone.stages.2.blocks.9.attn.w_msa.qkv.bias, backbone.stages.2.blocks.9.attn.w_msa.proj.weight, backbone.stages.2.blocks.9.attn.w_msa.proj.bias, backbone.stages.2.blocks.9.norm2.weight, backbone.stages.2.blocks.9.norm2.bias, backbone.stages.2.blocks.9.ffn.layers.0.0.weight, backbone.stages.2.blocks.9.ffn.layers.0.0.bias, backbone.stages.2.blocks.9.ffn.layers.1.weight, backbone.stages.2.blocks.9.ffn.layers.1.bias, backbone.stages.2.blocks.10.norm1.weight, backbone.stages.2.blocks.10.norm1.bias, backbone.stages.2.blocks.10.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.10.attn.w_msa.relative_position_index, backbone.stages.2.blocks.10.attn.w_msa.qkv.weight, backbone.stages.2.blocks.10.attn.w_msa.qkv.bias, backbone.stages.2.blocks.10.attn.w_msa.proj.weight, backbone.stages.2.blocks.10.attn.w_msa.proj.bias, backbone.stages.2.blocks.10.norm2.weight, backbone.stages.2.blocks.10.norm2.bias, backbone.stages.2.blocks.10.ffn.layers.0.0.weight, backbone.stages.2.blocks.10.ffn.layers.0.0.bias, backbone.stages.2.blocks.10.ffn.layers.1.weight, backbone.stages.2.blocks.10.ffn.layers.1.bias, backbone.stages.2.blocks.11.norm1.weight, backbone.stages.2.blocks.11.norm1.bias, backbone.stages.2.blocks.11.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.11.attn.w_msa.relative_position_index, backbone.stages.2.blocks.11.attn.w_msa.qkv.weight, backbone.stages.2.blocks.11.attn.w_msa.qkv.bias, backbone.stages.2.blocks.11.attn.w_msa.proj.weight, backbone.stages.2.blocks.11.attn.w_msa.proj.bias, backbone.stages.2.blocks.11.norm2.weight, backbone.stages.2.blocks.11.norm2.bias, backbone.stages.2.blocks.11.ffn.layers.0.0.weight, backbone.stages.2.blocks.11.ffn.layers.0.0.bias, backbone.stages.2.blocks.11.ffn.layers.1.weight, backbone.stages.2.blocks.11.ffn.layers.1.bias, backbone.stages.2.blocks.12.norm1.weight, backbone.stages.2.blocks.12.norm1.bias, backbone.stages.2.blocks.12.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.12.attn.w_msa.relative_position_index, backbone.stages.2.blocks.12.attn.w_msa.qkv.weight, backbone.stages.2.blocks.12.attn.w_msa.qkv.bias, backbone.stages.2.blocks.12.attn.w_msa.proj.weight, backbone.stages.2.blocks.12.attn.w_msa.proj.bias, backbone.stages.2.blocks.12.norm2.weight, backbone.stages.2.blocks.12.norm2.bias, backbone.stages.2.blocks.12.ffn.layers.0.0.weight, backbone.stages.2.blocks.12.ffn.layers.0.0.bias, backbone.stages.2.blocks.12.ffn.layers.1.weight, backbone.stages.2.blocks.12.ffn.layers.1.bias, backbone.stages.2.blocks.13.norm1.weight, backbone.stages.2.blocks.13.norm1.bias, backbone.stages.2.blocks.13.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.13.attn.w_msa.relative_position_index, backbone.stages.2.blocks.13.attn.w_msa.qkv.weight, backbone.stages.2.blocks.13.attn.w_msa.qkv.bias, backbone.stages.2.blocks.13.attn.w_msa.proj.weight, backbone.stages.2.blocks.13.attn.w_msa.proj.bias, backbone.stages.2.blocks.13.norm2.weight, backbone.stages.2.blocks.13.norm2.bias, backbone.stages.2.blocks.13.ffn.layers.0.0.weight, backbone.stages.2.blocks.13.ffn.layers.0.0.bias, backbone.stages.2.blocks.13.ffn.layers.1.weight, backbone.stages.2.blocks.13.ffn.layers.1.bias, backbone.stages.2.blocks.14.norm1.weight, backbone.stages.2.blocks.14.norm1.bias, backbone.stages.2.blocks.14.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.14.attn.w_msa.relative_position_index, backbone.stages.2.blocks.14.attn.w_msa.qkv.weight, backbone.stages.2.blocks.14.attn.w_msa.qkv.bias, backbone.stages.2.blocks.14.attn.w_msa.proj.weight, backbone.stages.2.blocks.14.attn.w_msa.proj.bias, backbone.stages.2.blocks.14.norm2.weight, backbone.stages.2.blocks.14.norm2.bias, backbone.stages.2.blocks.14.ffn.layers.0.0.weight, backbone.stages.2.blocks.14.ffn.layers.0.0.bias, backbone.stages.2.blocks.14.ffn.layers.1.weight, backbone.stages.2.blocks.14.ffn.layers.1.bias, backbone.stages.2.blocks.15.norm1.weight, backbone.stages.2.blocks.15.norm1.bias, backbone.stages.2.blocks.15.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.15.attn.w_msa.relative_position_index, backbone.stages.2.blocks.15.attn.w_msa.qkv.weight, backbone.stages.2.blocks.15.attn.w_msa.qkv.bias, backbone.stages.2.blocks.15.attn.w_msa.proj.weight, backbone.stages.2.blocks.15.attn.w_msa.proj.bias, backbone.stages.2.blocks.15.norm2.weight, backbone.stages.2.blocks.15.norm2.bias, backbone.stages.2.blocks.15.ffn.layers.0.0.weight, backbone.stages.2.blocks.15.ffn.layers.0.0.bias, backbone.stages.2.blocks.15.ffn.layers.1.weight, backbone.stages.2.blocks.15.ffn.layers.1.bias, backbone.stages.2.blocks.16.norm1.weight, backbone.stages.2.blocks.16.norm1.bias, backbone.stages.2.blocks.16.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.16.attn.w_msa.relative_position_index, backbone.stages.2.blocks.16.attn.w_msa.qkv.weight, backbone.stages.2.blocks.16.attn.w_msa.qkv.bias, backbone.stages.2.blocks.16.attn.w_msa.proj.weight, backbone.stages.2.blocks.16.attn.w_msa.proj.bias, backbone.stages.2.blocks.16.norm2.weight, backbone.stages.2.blocks.16.norm2.bias, backbone.stages.2.blocks.16.ffn.layers.0.0.weight, backbone.stages.2.blocks.16.ffn.layers.0.0.bias, backbone.stages.2.blocks.16.ffn.layers.1.weight, backbone.stages.2.blocks.16.ffn.layers.1.bias, backbone.stages.2.blocks.17.norm1.weight, backbone.stages.2.blocks.17.norm1.bias, backbone.stages.2.blocks.17.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.17.attn.w_msa.relative_position_index, backbone.stages.2.blocks.17.attn.w_msa.qkv.weight, backbone.stages.2.blocks.17.attn.w_msa.qkv.bias, backbone.stages.2.blocks.17.attn.w_msa.proj.weight, backbone.stages.2.blocks.17.attn.w_msa.proj.bias, backbone.stages.2.blocks.17.norm2.weight, backbone.stages.2.blocks.17.norm2.bias, backbone.stages.2.blocks.17.ffn.layers.0.0.weight, backbone.stages.2.blocks.17.ffn.layers.0.0.bias, backbone.stages.2.blocks.17.ffn.layers.1.weight, backbone.stages.2.blocks.17.ffn.layers.1.bias, backbone.stages.2.downsample.norm.weight, backbone.stages.2.downsample.norm.bias, backbone.stages.2.downsample.reduction.weight, backbone.stages.3.blocks.0.norm1.weight, backbone.stages.3.blocks.0.norm1.bias, backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table, backbone.stages.3.blocks.0.attn.w_msa.relative_position_index, backbone.stages.3.blocks.0.attn.w_msa.qkv.weight, backbone.stages.3.blocks.0.attn.w_msa.qkv.bias, backbone.stages.3.blocks.0.attn.w_msa.proj.weight, backbone.stages.3.blocks.0.attn.w_msa.proj.bias, backbone.stages.3.blocks.0.norm2.weight, backbone.stages.3.blocks.0.norm2.bias, backbone.stages.3.blocks.0.ffn.layers.0.0.weight, backbone.stages.3.blocks.0.ffn.layers.0.0.bias, backbone.stages.3.blocks.0.ffn.layers.1.weight, backbone.stages.3.blocks.0.ffn.layers.1.bias, backbone.stages.3.blocks.1.norm1.weight, backbone.stages.3.blocks.1.norm1.bias, backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table, backbone.stages.3.blocks.1.attn.w_msa.relative_position_index, backbone.stages.3.blocks.1.attn.w_msa.qkv.weight, backbone.stages.3.blocks.1.attn.w_msa.qkv.bias, backbone.stages.3.blocks.1.attn.w_msa.proj.weight, backbone.stages.3.blocks.1.attn.w_msa.proj.bias, backbone.stages.3.blocks.1.norm2.weight, backbone.stages.3.blocks.1.norm2.bias, backbone.stages.3.blocks.1.ffn.layers.0.0.weight, backbone.stages.3.blocks.1.ffn.layers.0.0.bias, backbone.stages.3.blocks.1.ffn.layers.1.weight, backbone.stages.3.blocks.1.ffn.layers.1.bias, backbone.norm0.weight, backbone.norm0.bias, backbone.norm1.weight, backbone.norm1.bias, backbone.norm2.weight, backbone.norm2.bias, backbone.norm3.weight, backbone.norm3.bias\n",
      "\n",
      "missing keys in source state_dict: level_embed, backbone.conv1.weight, backbone.bn1.weight, backbone.bn1.bias, backbone.bn1.running_mean, backbone.bn1.running_var, backbone.layer1.0.conv1.weight, backbone.layer1.0.bn1.weight, backbone.layer1.0.bn1.bias, backbone.layer1.0.bn1.running_mean, backbone.layer1.0.bn1.running_var, backbone.layer1.0.conv2.weight, backbone.layer1.0.bn2.weight, backbone.layer1.0.bn2.bias, backbone.layer1.0.bn2.running_mean, backbone.layer1.0.bn2.running_var, backbone.layer1.0.conv3.weight, backbone.layer1.0.bn3.weight, backbone.layer1.0.bn3.bias, backbone.layer1.0.bn3.running_mean, backbone.layer1.0.bn3.running_var, backbone.layer1.0.downsample.0.weight, backbone.layer1.0.downsample.1.weight, backbone.layer1.0.downsample.1.bias, backbone.layer1.0.downsample.1.running_mean, backbone.layer1.0.downsample.1.running_var, backbone.layer1.1.conv1.weight, backbone.layer1.1.bn1.weight, backbone.layer1.1.bn1.bias, backbone.layer1.1.bn1.running_mean, backbone.layer1.1.bn1.running_var, backbone.layer1.1.conv2.weight, backbone.layer1.1.bn2.weight, backbone.layer1.1.bn2.bias, backbone.layer1.1.bn2.running_mean, backbone.layer1.1.bn2.running_var, backbone.layer1.1.conv3.weight, backbone.layer1.1.bn3.weight, backbone.layer1.1.bn3.bias, backbone.layer1.1.bn3.running_mean, backbone.layer1.1.bn3.running_var, backbone.layer1.2.conv1.weight, backbone.layer1.2.bn1.weight, backbone.layer1.2.bn1.bias, backbone.layer1.2.bn1.running_mean, backbone.layer1.2.bn1.running_var, backbone.layer1.2.conv2.weight, backbone.layer1.2.bn2.weight, backbone.layer1.2.bn2.bias, backbone.layer1.2.bn2.running_mean, backbone.layer1.2.bn2.running_var, backbone.layer1.2.conv3.weight, backbone.layer1.2.bn3.weight, backbone.layer1.2.bn3.bias, backbone.layer1.2.bn3.running_mean, backbone.layer1.2.bn3.running_var, backbone.layer2.0.conv1.weight, backbone.layer2.0.bn1.weight, backbone.layer2.0.bn1.bias, backbone.layer2.0.bn1.running_mean, backbone.layer2.0.bn1.running_var, backbone.layer2.0.conv2.weight, backbone.layer2.0.bn2.weight, backbone.layer2.0.bn2.bias, backbone.layer2.0.bn2.running_mean, backbone.layer2.0.bn2.running_var, backbone.layer2.0.conv3.weight, backbone.layer2.0.bn3.weight, backbone.layer2.0.bn3.bias, backbone.layer2.0.bn3.running_mean, backbone.layer2.0.bn3.running_var, backbone.layer2.0.downsample.0.weight, backbone.layer2.0.downsample.1.weight, backbone.layer2.0.downsample.1.bias, backbone.layer2.0.downsample.1.running_mean, backbone.layer2.0.downsample.1.running_var, backbone.layer2.1.conv1.weight, backbone.layer2.1.bn1.weight, backbone.layer2.1.bn1.bias, backbone.layer2.1.bn1.running_mean, backbone.layer2.1.bn1.running_var, backbone.layer2.1.conv2.weight, backbone.layer2.1.bn2.weight, backbone.layer2.1.bn2.bias, backbone.layer2.1.bn2.running_mean, backbone.layer2.1.bn2.running_var, backbone.layer2.1.conv3.weight, backbone.layer2.1.bn3.weight, backbone.layer2.1.bn3.bias, backbone.layer2.1.bn3.running_mean, backbone.layer2.1.bn3.running_var, backbone.layer2.2.conv1.weight, backbone.layer2.2.bn1.weight, backbone.layer2.2.bn1.bias, backbone.layer2.2.bn1.running_mean, backbone.layer2.2.bn1.running_var, backbone.layer2.2.conv2.weight, backbone.layer2.2.bn2.weight, backbone.layer2.2.bn2.bias, backbone.layer2.2.bn2.running_mean, backbone.layer2.2.bn2.running_var, backbone.layer2.2.conv3.weight, backbone.layer2.2.bn3.weight, backbone.layer2.2.bn3.bias, backbone.layer2.2.bn3.running_mean, backbone.layer2.2.bn3.running_var, backbone.layer2.3.conv1.weight, backbone.layer2.3.bn1.weight, backbone.layer2.3.bn1.bias, backbone.layer2.3.bn1.running_mean, backbone.layer2.3.bn1.running_var, backbone.layer2.3.conv2.weight, backbone.layer2.3.bn2.weight, backbone.layer2.3.bn2.bias, backbone.layer2.3.bn2.running_mean, backbone.layer2.3.bn2.running_var, backbone.layer2.3.conv3.weight, backbone.layer2.3.bn3.weight, backbone.layer2.3.bn3.bias, backbone.layer2.3.bn3.running_mean, backbone.layer2.3.bn3.running_var, backbone.layer3.0.conv1.weight, backbone.layer3.0.bn1.weight, backbone.layer3.0.bn1.bias, backbone.layer3.0.bn1.running_mean, backbone.layer3.0.bn1.running_var, backbone.layer3.0.conv2.weight, backbone.layer3.0.bn2.weight, backbone.layer3.0.bn2.bias, backbone.layer3.0.bn2.running_mean, backbone.layer3.0.bn2.running_var, backbone.layer3.0.conv3.weight, backbone.layer3.0.bn3.weight, backbone.layer3.0.bn3.bias, backbone.layer3.0.bn3.running_mean, backbone.layer3.0.bn3.running_var, backbone.layer3.0.downsample.0.weight, backbone.layer3.0.downsample.1.weight, backbone.layer3.0.downsample.1.bias, backbone.layer3.0.downsample.1.running_mean, backbone.layer3.0.downsample.1.running_var, backbone.layer3.1.conv1.weight, backbone.layer3.1.bn1.weight, backbone.layer3.1.bn1.bias, backbone.layer3.1.bn1.running_mean, backbone.layer3.1.bn1.running_var, backbone.layer3.1.conv2.weight, backbone.layer3.1.bn2.weight, backbone.layer3.1.bn2.bias, backbone.layer3.1.bn2.running_mean, backbone.layer3.1.bn2.running_var, backbone.layer3.1.conv3.weight, backbone.layer3.1.bn3.weight, backbone.layer3.1.bn3.bias, backbone.layer3.1.bn3.running_mean, backbone.layer3.1.bn3.running_var, backbone.layer3.2.conv1.weight, backbone.layer3.2.bn1.weight, backbone.layer3.2.bn1.bias, backbone.layer3.2.bn1.running_mean, backbone.layer3.2.bn1.running_var, backbone.layer3.2.conv2.weight, backbone.layer3.2.bn2.weight, backbone.layer3.2.bn2.bias, backbone.layer3.2.bn2.running_mean, backbone.layer3.2.bn2.running_var, backbone.layer3.2.conv3.weight, backbone.layer3.2.bn3.weight, backbone.layer3.2.bn3.bias, backbone.layer3.2.bn3.running_mean, backbone.layer3.2.bn3.running_var, backbone.layer3.3.conv1.weight, backbone.layer3.3.bn1.weight, backbone.layer3.3.bn1.bias, backbone.layer3.3.bn1.running_mean, backbone.layer3.3.bn1.running_var, backbone.layer3.3.conv2.weight, backbone.layer3.3.bn2.weight, backbone.layer3.3.bn2.bias, backbone.layer3.3.bn2.running_mean, backbone.layer3.3.bn2.running_var, backbone.layer3.3.conv3.weight, backbone.layer3.3.bn3.weight, backbone.layer3.3.bn3.bias, backbone.layer3.3.bn3.running_mean, backbone.layer3.3.bn3.running_var, backbone.layer3.4.conv1.weight, backbone.layer3.4.bn1.weight, backbone.layer3.4.bn1.bias, backbone.layer3.4.bn1.running_mean, backbone.layer3.4.bn1.running_var, backbone.layer3.4.conv2.weight, backbone.layer3.4.bn2.weight, backbone.layer3.4.bn2.bias, backbone.layer3.4.bn2.running_mean, backbone.layer3.4.bn2.running_var, backbone.layer3.4.conv3.weight, backbone.layer3.4.bn3.weight, backbone.layer3.4.bn3.bias, backbone.layer3.4.bn3.running_mean, backbone.layer3.4.bn3.running_var, backbone.layer3.5.conv1.weight, backbone.layer3.5.bn1.weight, backbone.layer3.5.bn1.bias, backbone.layer3.5.bn1.running_mean, backbone.layer3.5.bn1.running_var, backbone.layer3.5.conv2.weight, backbone.layer3.5.bn2.weight, backbone.layer3.5.bn2.bias, backbone.layer3.5.bn2.running_mean, backbone.layer3.5.bn2.running_var, backbone.layer3.5.conv3.weight, backbone.layer3.5.bn3.weight, backbone.layer3.5.bn3.bias, backbone.layer3.5.bn3.running_mean, backbone.layer3.5.bn3.running_var, backbone.layer4.0.conv1.weight, backbone.layer4.0.bn1.weight, backbone.layer4.0.bn1.bias, backbone.layer4.0.bn1.running_mean, backbone.layer4.0.bn1.running_var, backbone.layer4.0.conv2.weight, backbone.layer4.0.bn2.weight, backbone.layer4.0.bn2.bias, backbone.layer4.0.bn2.running_mean, backbone.layer4.0.bn2.running_var, backbone.layer4.0.conv3.weight, backbone.layer4.0.bn3.weight, backbone.layer4.0.bn3.bias, backbone.layer4.0.bn3.running_mean, backbone.layer4.0.bn3.running_var, backbone.layer4.0.downsample.0.weight, backbone.layer4.0.downsample.1.weight, backbone.layer4.0.downsample.1.bias, backbone.layer4.0.downsample.1.running_mean, backbone.layer4.0.downsample.1.running_var, backbone.layer4.1.conv1.weight, backbone.layer4.1.bn1.weight, backbone.layer4.1.bn1.bias, backbone.layer4.1.bn1.running_mean, backbone.layer4.1.bn1.running_var, backbone.layer4.1.conv2.weight, backbone.layer4.1.bn2.weight, backbone.layer4.1.bn2.bias, backbone.layer4.1.bn2.running_mean, backbone.layer4.1.bn2.running_var, backbone.layer4.1.conv3.weight, backbone.layer4.1.bn3.weight, backbone.layer4.1.bn3.bias, backbone.layer4.1.bn3.running_mean, backbone.layer4.1.bn3.running_var, backbone.layer4.2.conv1.weight, backbone.layer4.2.bn1.weight, backbone.layer4.2.bn1.bias, backbone.layer4.2.bn1.running_mean, backbone.layer4.2.bn1.running_var, backbone.layer4.2.conv2.weight, backbone.layer4.2.bn2.weight, backbone.layer4.2.bn2.bias, backbone.layer4.2.bn2.running_mean, backbone.layer4.2.bn2.running_var, backbone.layer4.2.conv3.weight, backbone.layer4.2.bn3.weight, backbone.layer4.2.bn3.bias, backbone.layer4.2.bn3.running_mean, backbone.layer4.2.bn3.running_var, neck.convs.0.conv.weight, neck.convs.0.gn.weight, neck.convs.0.gn.bias, neck.convs.1.conv.weight, neck.convs.1.gn.weight, neck.convs.1.gn.bias, neck.convs.2.conv.weight, neck.convs.2.gn.weight, neck.convs.2.gn.bias, neck.extra_convs.0.conv.weight, neck.extra_convs.0.gn.weight, neck.extra_convs.0.gn.bias, bbox_head.cls_branches.0.weight, bbox_head.cls_branches.0.bias, bbox_head.cls_branches.1.weight, bbox_head.cls_branches.1.bias, bbox_head.cls_branches.2.weight, bbox_head.cls_branches.2.bias, bbox_head.cls_branches.3.weight, bbox_head.cls_branches.3.bias, bbox_head.cls_branches.4.weight, bbox_head.cls_branches.4.bias, bbox_head.cls_branches.5.weight, bbox_head.cls_branches.5.bias, bbox_head.cls_branches.6.weight, bbox_head.cls_branches.6.bias, bbox_head.reg_branches.0.0.weight, bbox_head.reg_branches.0.0.bias, bbox_head.reg_branches.0.2.weight, bbox_head.reg_branches.0.2.bias, bbox_head.reg_branches.0.4.weight, bbox_head.reg_branches.0.4.bias, bbox_head.reg_branches.1.0.weight, bbox_head.reg_branches.1.0.bias, bbox_head.reg_branches.1.2.weight, bbox_head.reg_branches.1.2.bias, bbox_head.reg_branches.1.4.weight, bbox_head.reg_branches.1.4.bias, bbox_head.reg_branches.2.0.weight, bbox_head.reg_branches.2.0.bias, bbox_head.reg_branches.2.2.weight, bbox_head.reg_branches.2.2.bias, bbox_head.reg_branches.2.4.weight, bbox_head.reg_branches.2.4.bias, bbox_head.reg_branches.3.0.weight, bbox_head.reg_branches.3.0.bias, bbox_head.reg_branches.3.2.weight, bbox_head.reg_branches.3.2.bias, bbox_head.reg_branches.3.4.weight, bbox_head.reg_branches.3.4.bias, bbox_head.reg_branches.4.0.weight, bbox_head.reg_branches.4.0.bias, bbox_head.reg_branches.4.2.weight, bbox_head.reg_branches.4.2.bias, bbox_head.reg_branches.4.4.weight, bbox_head.reg_branches.4.4.bias, bbox_head.reg_branches.5.0.weight, bbox_head.reg_branches.5.0.bias, bbox_head.reg_branches.5.2.weight, bbox_head.reg_branches.5.2.bias, bbox_head.reg_branches.5.4.weight, bbox_head.reg_branches.5.4.bias, bbox_head.reg_branches.6.0.weight, bbox_head.reg_branches.6.0.bias, bbox_head.reg_branches.6.2.weight, bbox_head.reg_branches.6.2.bias, bbox_head.reg_branches.6.4.weight, bbox_head.reg_branches.6.4.bias, encoder.layers.0.self_attn.sampling_offsets.weight, encoder.layers.0.self_attn.sampling_offsets.bias, encoder.layers.0.self_attn.attention_weights.weight, encoder.layers.0.self_attn.attention_weights.bias, encoder.layers.0.self_attn.value_proj.weight, encoder.layers.0.self_attn.value_proj.bias, encoder.layers.0.self_attn.output_proj.weight, encoder.layers.0.self_attn.output_proj.bias, encoder.layers.0.ffn.layers.0.0.weight, encoder.layers.0.ffn.layers.0.0.bias, encoder.layers.0.ffn.layers.1.weight, encoder.layers.0.ffn.layers.1.bias, encoder.layers.0.norms.0.weight, encoder.layers.0.norms.0.bias, encoder.layers.0.norms.1.weight, encoder.layers.0.norms.1.bias, encoder.layers.1.self_attn.sampling_offsets.weight, encoder.layers.1.self_attn.sampling_offsets.bias, encoder.layers.1.self_attn.attention_weights.weight, encoder.layers.1.self_attn.attention_weights.bias, encoder.layers.1.self_attn.value_proj.weight, encoder.layers.1.self_attn.value_proj.bias, encoder.layers.1.self_attn.output_proj.weight, encoder.layers.1.self_attn.output_proj.bias, encoder.layers.1.ffn.layers.0.0.weight, encoder.layers.1.ffn.layers.0.0.bias, encoder.layers.1.ffn.layers.1.weight, encoder.layers.1.ffn.layers.1.bias, encoder.layers.1.norms.0.weight, encoder.layers.1.norms.0.bias, encoder.layers.1.norms.1.weight, encoder.layers.1.norms.1.bias, encoder.layers.2.self_attn.sampling_offsets.weight, encoder.layers.2.self_attn.sampling_offsets.bias, encoder.layers.2.self_attn.attention_weights.weight, encoder.layers.2.self_attn.attention_weights.bias, encoder.layers.2.self_attn.value_proj.weight, encoder.layers.2.self_attn.value_proj.bias, encoder.layers.2.self_attn.output_proj.weight, encoder.layers.2.self_attn.output_proj.bias, encoder.layers.2.ffn.layers.0.0.weight, encoder.layers.2.ffn.layers.0.0.bias, encoder.layers.2.ffn.layers.1.weight, encoder.layers.2.ffn.layers.1.bias, encoder.layers.2.norms.0.weight, encoder.layers.2.norms.0.bias, encoder.layers.2.norms.1.weight, encoder.layers.2.norms.1.bias, encoder.layers.3.self_attn.sampling_offsets.weight, encoder.layers.3.self_attn.sampling_offsets.bias, encoder.layers.3.self_attn.attention_weights.weight, encoder.layers.3.self_attn.attention_weights.bias, encoder.layers.3.self_attn.value_proj.weight, encoder.layers.3.self_attn.value_proj.bias, encoder.layers.3.self_attn.output_proj.weight, encoder.layers.3.self_attn.output_proj.bias, encoder.layers.3.ffn.layers.0.0.weight, encoder.layers.3.ffn.layers.0.0.bias, encoder.layers.3.ffn.layers.1.weight, encoder.layers.3.ffn.layers.1.bias, encoder.layers.3.norms.0.weight, encoder.layers.3.norms.0.bias, encoder.layers.3.norms.1.weight, encoder.layers.3.norms.1.bias, encoder.layers.4.self_attn.sampling_offsets.weight, encoder.layers.4.self_attn.sampling_offsets.bias, encoder.layers.4.self_attn.attention_weights.weight, encoder.layers.4.self_attn.attention_weights.bias, encoder.layers.4.self_attn.value_proj.weight, encoder.layers.4.self_attn.value_proj.bias, encoder.layers.4.self_attn.output_proj.weight, encoder.layers.4.self_attn.output_proj.bias, encoder.layers.4.ffn.layers.0.0.weight, encoder.layers.4.ffn.layers.0.0.bias, encoder.layers.4.ffn.layers.1.weight, encoder.layers.4.ffn.layers.1.bias, encoder.layers.4.norms.0.weight, encoder.layers.4.norms.0.bias, encoder.layers.4.norms.1.weight, encoder.layers.4.norms.1.bias, encoder.layers.5.self_attn.sampling_offsets.weight, encoder.layers.5.self_attn.sampling_offsets.bias, encoder.layers.5.self_attn.attention_weights.weight, encoder.layers.5.self_attn.attention_weights.bias, encoder.layers.5.self_attn.value_proj.weight, encoder.layers.5.self_attn.value_proj.bias, encoder.layers.5.self_attn.output_proj.weight, encoder.layers.5.self_attn.output_proj.bias, encoder.layers.5.ffn.layers.0.0.weight, encoder.layers.5.ffn.layers.0.0.bias, encoder.layers.5.ffn.layers.1.weight, encoder.layers.5.ffn.layers.1.bias, encoder.layers.5.norms.0.weight, encoder.layers.5.norms.0.bias, encoder.layers.5.norms.1.weight, encoder.layers.5.norms.1.bias, decoder.layers.0.self_attn.attn.in_proj_weight, decoder.layers.0.self_attn.attn.in_proj_bias, decoder.layers.0.self_attn.attn.out_proj.weight, decoder.layers.0.self_attn.attn.out_proj.bias, decoder.layers.0.cross_attn.sampling_offsets.weight, decoder.layers.0.cross_attn.sampling_offsets.bias, decoder.layers.0.cross_attn.attention_weights.weight, decoder.layers.0.cross_attn.attention_weights.bias, decoder.layers.0.cross_attn.value_proj.weight, decoder.layers.0.cross_attn.value_proj.bias, decoder.layers.0.cross_attn.output_proj.weight, decoder.layers.0.cross_attn.output_proj.bias, decoder.layers.0.ffn.layers.0.0.weight, decoder.layers.0.ffn.layers.0.0.bias, decoder.layers.0.ffn.layers.1.weight, decoder.layers.0.ffn.layers.1.bias, decoder.layers.0.norms.0.weight, decoder.layers.0.norms.0.bias, decoder.layers.0.norms.1.weight, decoder.layers.0.norms.1.bias, decoder.layers.0.norms.2.weight, decoder.layers.0.norms.2.bias, decoder.layers.1.self_attn.attn.in_proj_weight, decoder.layers.1.self_attn.attn.in_proj_bias, decoder.layers.1.self_attn.attn.out_proj.weight, decoder.layers.1.self_attn.attn.out_proj.bias, decoder.layers.1.cross_attn.sampling_offsets.weight, decoder.layers.1.cross_attn.sampling_offsets.bias, decoder.layers.1.cross_attn.attention_weights.weight, decoder.layers.1.cross_attn.attention_weights.bias, decoder.layers.1.cross_attn.value_proj.weight, decoder.layers.1.cross_attn.value_proj.bias, decoder.layers.1.cross_attn.output_proj.weight, decoder.layers.1.cross_attn.output_proj.bias, decoder.layers.1.ffn.layers.0.0.weight, decoder.layers.1.ffn.layers.0.0.bias, decoder.layers.1.ffn.layers.1.weight, decoder.layers.1.ffn.layers.1.bias, decoder.layers.1.norms.0.weight, decoder.layers.1.norms.0.bias, decoder.layers.1.norms.1.weight, decoder.layers.1.norms.1.bias, decoder.layers.1.norms.2.weight, decoder.layers.1.norms.2.bias, decoder.layers.2.self_attn.attn.in_proj_weight, decoder.layers.2.self_attn.attn.in_proj_bias, decoder.layers.2.self_attn.attn.out_proj.weight, decoder.layers.2.self_attn.attn.out_proj.bias, decoder.layers.2.cross_attn.sampling_offsets.weight, decoder.layers.2.cross_attn.sampling_offsets.bias, decoder.layers.2.cross_attn.attention_weights.weight, decoder.layers.2.cross_attn.attention_weights.bias, decoder.layers.2.cross_attn.value_proj.weight, decoder.layers.2.cross_attn.value_proj.bias, decoder.layers.2.cross_attn.output_proj.weight, decoder.layers.2.cross_attn.output_proj.bias, decoder.layers.2.ffn.layers.0.0.weight, decoder.layers.2.ffn.layers.0.0.bias, decoder.layers.2.ffn.layers.1.weight, decoder.layers.2.ffn.layers.1.bias, decoder.layers.2.norms.0.weight, decoder.layers.2.norms.0.bias, decoder.layers.2.norms.1.weight, decoder.layers.2.norms.1.bias, decoder.layers.2.norms.2.weight, decoder.layers.2.norms.2.bias, decoder.layers.3.self_attn.attn.in_proj_weight, decoder.layers.3.self_attn.attn.in_proj_bias, decoder.layers.3.self_attn.attn.out_proj.weight, decoder.layers.3.self_attn.attn.out_proj.bias, decoder.layers.3.cross_attn.sampling_offsets.weight, decoder.layers.3.cross_attn.sampling_offsets.bias, decoder.layers.3.cross_attn.attention_weights.weight, decoder.layers.3.cross_attn.attention_weights.bias, decoder.layers.3.cross_attn.value_proj.weight, decoder.layers.3.cross_attn.value_proj.bias, decoder.layers.3.cross_attn.output_proj.weight, decoder.layers.3.cross_attn.output_proj.bias, decoder.layers.3.ffn.layers.0.0.weight, decoder.layers.3.ffn.layers.0.0.bias, decoder.layers.3.ffn.layers.1.weight, decoder.layers.3.ffn.layers.1.bias, decoder.layers.3.norms.0.weight, decoder.layers.3.norms.0.bias, decoder.layers.3.norms.1.weight, decoder.layers.3.norms.1.bias, decoder.layers.3.norms.2.weight, decoder.layers.3.norms.2.bias, decoder.layers.4.self_attn.attn.in_proj_weight, decoder.layers.4.self_attn.attn.in_proj_bias, decoder.layers.4.self_attn.attn.out_proj.weight, decoder.layers.4.self_attn.attn.out_proj.bias, decoder.layers.4.cross_attn.sampling_offsets.weight, decoder.layers.4.cross_attn.sampling_offsets.bias, decoder.layers.4.cross_attn.attention_weights.weight, decoder.layers.4.cross_attn.attention_weights.bias, decoder.layers.4.cross_attn.value_proj.weight, decoder.layers.4.cross_attn.value_proj.bias, decoder.layers.4.cross_attn.output_proj.weight, decoder.layers.4.cross_attn.output_proj.bias, decoder.layers.4.ffn.layers.0.0.weight, decoder.layers.4.ffn.layers.0.0.bias, decoder.layers.4.ffn.layers.1.weight, decoder.layers.4.ffn.layers.1.bias, decoder.layers.4.norms.0.weight, decoder.layers.4.norms.0.bias, decoder.layers.4.norms.1.weight, decoder.layers.4.norms.1.bias, decoder.layers.4.norms.2.weight, decoder.layers.4.norms.2.bias, decoder.layers.5.self_attn.attn.in_proj_weight, decoder.layers.5.self_attn.attn.in_proj_bias, decoder.layers.5.self_attn.attn.out_proj.weight, decoder.layers.5.self_attn.attn.out_proj.bias, decoder.layers.5.cross_attn.sampling_offsets.weight, decoder.layers.5.cross_attn.sampling_offsets.bias, decoder.layers.5.cross_attn.attention_weights.weight, decoder.layers.5.cross_attn.attention_weights.bias, decoder.layers.5.cross_attn.value_proj.weight, decoder.layers.5.cross_attn.value_proj.bias, decoder.layers.5.cross_attn.output_proj.weight, decoder.layers.5.cross_attn.output_proj.bias, decoder.layers.5.ffn.layers.0.0.weight, decoder.layers.5.ffn.layers.0.0.bias, decoder.layers.5.ffn.layers.1.weight, decoder.layers.5.ffn.layers.1.bias, decoder.layers.5.norms.0.weight, decoder.layers.5.norms.0.bias, decoder.layers.5.norms.1.weight, decoder.layers.5.norms.1.bias, decoder.layers.5.norms.2.weight, decoder.layers.5.norms.2.bias, decoder.ref_point_head.layers.0.weight, decoder.ref_point_head.layers.0.bias, decoder.ref_point_head.layers.1.weight, decoder.ref_point_head.layers.1.bias, decoder.norm.weight, decoder.norm.bias, query_embedding.weight, memory_trans_fc.weight, memory_trans_fc.bias, memory_trans_norm.weight, memory_trans_norm.bias, dn_query_generator.label_embedding.weight\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\philmarq\\miniconda3\\envs\\mmtest\\lib\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3484.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 33\u001b[0m\n\u001b[0;32m     28\u001b[0m result \u001b[38;5;241m=\u001b[39m inference_detector(model, img)\n\u001b[0;32m     32\u001b[0m color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m255\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 33\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m orig \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m#image[image>0] = 0\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "#import pydensecrf.densecrf as dcrf\n",
    "\n",
    "from mmdet.apis import init_detector, inference_detector\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "\n",
    "config_file = r\"C:\\Users\\philmarq\\source\\repos\\MMWrapperRepo\\firstapitest\\20230804_162325\\vis_data\\config.py\"\n",
    "checkpoint_file = r\"C:\\Users\\philmarq\\source\\repos\\MMWrapperRepo\\firstapitest\\best_coco_bbox_mAP_epoch_25.pth\"\n",
    "\n",
    "device = 'cuda:0'\n",
    "\n",
    "model = init_detector(config_file, checkpoint_file, device=device)\n",
    "\n",
    "# Load image\n",
    "\n",
    "\n",
    "colors = [(255,0,0), (125,0,0), (0,255,0), (50, 255,0), (0,25,255), (0, 125, 0)]\n",
    "root = r\"C:\\HSA\\HSA-Data\\projects\\d55090aa-a315-4ae3-8242-b50e13e355f6\\dataset\\train2017\"\n",
    "for file in os.listdir(root):\n",
    "    img = os.path.join(root, file)\n",
    "    result = inference_detector(model, img)\n",
    "    \n",
    "    \n",
    "\n",
    "    color = (255,0,0)\n",
    "    image = cv2.imread(img)\n",
    "    orig = image.copy()\n",
    "\n",
    "    #image[image>0] = 0\n",
    "    masks = result.pred_instances.masks.cpu().numpy()\n",
    "    scores = result.pred_instances.scores.cpu().numpy()\n",
    "    labels = result.pred_instances.labels.cpu().numpy()\n",
    "    bboxes = result.pred_instances.bboxes.cpu().numpy()\n",
    "    thresh = 0.35\n",
    "    \n",
    "    for mask, score,label, bbox in zip(masks, scores,  labels, bboxes):\n",
    "        if score > thresh:\n",
    "            if label == 0:  # For label == 0, draw contours\n",
    "                mask = mask.astype(np.uint8)\n",
    "                contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                #contours = connect_closest_contours(contours, image, angle_tolerance = 5, fixed_threshold=50, pixel_threshold = 3)\n",
    "                #color  = np.random.rand(3) * 255\n",
    "                cv2.drawContours(image, contours, -1, color, -1)\n",
    "            else:  # For other labels, draw bounding boxes\n",
    "                color = colors[label]\n",
    "                x1, y1, x2, y2 = bbox.astype(np.int32)\n",
    "                cv2.rectangle(image, (x1, y1), (x2, y2), color, 1)\n",
    "    \n",
    "    cv2.imwrite(os.path.join(\"outputall\", file), image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c0b31a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmengine import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44bbd884",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = r\"C:\\Users\\philmarq\\source\\repos\\mmdetectionnew\\segmentationswins\\swin_s_upper.py\"\n",
    "is_detetion = Config.fromfile(config_file)['train_pipeline'][-1]['type'] #== \"PackDetInputs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0078c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PackSegInputs'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_detetion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6adf825c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmseg.apis import init_model, inference_model\n",
    "from mmdet.apis import init_detector, inference_detector\n",
    "\n",
    "class InferenceModel:\n",
    "    def __init__(self, checkpoint_file, config_file, device = \"cuda\"):\n",
    "        self.is_detection = Config.fromfile(config_file)['train_pipeline'][-1]['type'] == \"PackDetInputs\"\n",
    "        print(Config.fromfile(config_file)['train_pipeline'][-1])\n",
    "        print(self.is_detection)\n",
    "        if self.is_detection:\n",
    "            self.model = init_detector(config_file, checkpoint_file, device=device)\n",
    "            self.forward = inference_detector\n",
    "        else:\n",
    "            self.model = init_model(config_path, checkpoint_path, device=device)\n",
    "            self.forward = inference_model\n",
    "    def predict(self, imgs):\n",
    "        return self.forward(self.model, imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a632562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'PackSegInputs'}\n",
      "False\n",
      "09/04 00:24:24 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The current default scope \"mmdet\" is not \"mmseg\", `init_default_scope` will force set the currentdefault scope to \"mmseg\".\n",
      "Loads checkpoint by local backend from path: C:\\Users\\philmarq\\source\\repos\\MMWrapperRepo\\segmentationtest\\best_mIoU_epoch_67.pth\n"
     ]
    }
   ],
   "source": [
    "config_path = r\"C:\\Users\\philmarq\\source\\repos\\MMWrapperRepo\\segmentationtest\\20230805_125344\\vis_data\\config.py\"\n",
    "checkpoint_path = r\"C:\\Users\\philmarq\\source\\repos\\MMWrapperRepo\\segmentationtest\\best_mIoU_epoch_67.pth\"\n",
    "inf = InferenceModel(checkpoint_file, config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80b9c2f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<SegDataSample(\n",
       " \n",
       "     META INFORMATION\n",
       "     scale_factor: (0.25, 0.25)\n",
       "     img_path: 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\09_Gr2T4_1s_10r_0x_0y_.png'\n",
       "     ori_shape: (4096, 4096)\n",
       "     img_padding_size: (0, 0, 0, 0)\n",
       "     img_shape: (1024, 1024)\n",
       "     pad_shape: torch.Size([1024, 1024])\n",
       " \n",
       "     DATA FIELDS\n",
       "     pred_sem_seg: <PixelData(\n",
       "         \n",
       "             META INFORMATION\n",
       "         \n",
       "             DATA FIELDS\n",
       "             data: tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
       "                          [0, 0, 0,  ..., 0, 0, 0],\n",
       "                          [0, 0, 0,  ..., 0, 0, 0],\n",
       "                          ...,\n",
       "                          [0, 0, 0,  ..., 0, 0, 0],\n",
       "                          [0, 0, 0,  ..., 0, 0, 0],\n",
       "                          [0, 0, 0,  ..., 0, 0, 0]]], device='cuda:0')\n",
       "         ) at 0x1ceff868220>\n",
       "     seg_logits: <PixelData(\n",
       "         \n",
       "             META INFORMATION\n",
       "         \n",
       "             DATA FIELDS\n",
       "             data: tensor([[[8.3897e-01, 8.3897e-01, 8.3897e-01,  ..., 8.6928e-01,\n",
       "                           8.6928e-01, 8.6928e-01],\n",
       "                          [8.3897e-01, 8.3897e-01, 8.3897e-01,  ..., 8.6928e-01,\n",
       "                           8.6928e-01, 8.6928e-01],\n",
       "                          [8.3897e-01, 8.3897e-01, 8.3897e-01,  ..., 8.6928e-01,\n",
       "                           8.6928e-01, 8.6928e-01],\n",
       "                          ...,\n",
       "                          [7.1730e-01, 7.1730e-01, 7.1730e-01,  ..., 7.0152e-01,\n",
       "                           7.0152e-01, 7.0152e-01],\n",
       "                          [7.1730e-01, 7.1730e-01, 7.1730e-01,  ..., 7.0152e-01,\n",
       "                           7.0152e-01, 7.0152e-01],\n",
       "                          [7.1730e-01, 7.1730e-01, 7.1730e-01,  ..., 7.0152e-01,\n",
       "                           7.0152e-01, 7.0152e-01]],\n",
       "                 \n",
       "                         [[5.3991e-04, 5.3991e-04, 5.3991e-04,  ..., 5.5151e-04,\n",
       "                           5.5151e-04, 5.5151e-04],\n",
       "                          [5.3991e-04, 5.3991e-04, 5.3991e-04,  ..., 5.5151e-04,\n",
       "                           5.5151e-04, 5.5151e-04],\n",
       "                          [5.3991e-04, 5.3991e-04, 5.3991e-04,  ..., 5.5151e-04,\n",
       "                           5.5151e-04, 5.5151e-04],\n",
       "                          ...,\n",
       "                          [4.5510e-04, 4.5510e-04, 4.5510e-04,  ..., 4.4507e-04,\n",
       "                           4.4507e-04, 4.4507e-04],\n",
       "                          [4.5510e-04, 4.5510e-04, 4.5510e-04,  ..., 4.4507e-04,\n",
       "                           4.4507e-04, 4.4507e-04],\n",
       "                          [4.5510e-04, 4.5510e-04, 4.5510e-04,  ..., 4.4507e-04,\n",
       "                           4.4507e-04, 4.4507e-04]],\n",
       "                 \n",
       "                         [[3.9904e-04, 3.9904e-04, 3.9904e-04,  ..., 4.1316e-04,\n",
       "                           4.1316e-04, 4.1316e-04],\n",
       "                          [3.9904e-04, 3.9904e-04, 3.9904e-04,  ..., 4.1316e-04,\n",
       "                           4.1316e-04, 4.1316e-04],\n",
       "                          [3.9904e-04, 3.9904e-04, 3.9904e-04,  ..., 4.1316e-04,\n",
       "                           4.1316e-04, 4.1316e-04],\n",
       "                          ...,\n",
       "                          [3.4093e-04, 3.4093e-04, 3.4093e-04,  ..., 3.3342e-04,\n",
       "                           3.3342e-04, 3.3342e-04],\n",
       "                          [3.4093e-04, 3.4093e-04, 3.4093e-04,  ..., 3.3342e-04,\n",
       "                           3.3342e-04, 3.3342e-04],\n",
       "                          [3.4093e-04, 3.4093e-04, 3.4093e-04,  ..., 3.3342e-04,\n",
       "                           3.3342e-04, 3.3342e-04]],\n",
       "                 \n",
       "                         [[3.9067e-04, 3.9067e-04, 3.9067e-04,  ..., 4.0417e-04,\n",
       "                           4.0417e-04, 4.0417e-04],\n",
       "                          [3.9067e-04, 3.9067e-04, 3.9067e-04,  ..., 4.0417e-04,\n",
       "                           4.0417e-04, 4.0417e-04],\n",
       "                          [3.9067e-04, 3.9067e-04, 3.9067e-04,  ..., 4.0417e-04,\n",
       "                           4.0417e-04, 4.0417e-04],\n",
       "                          ...,\n",
       "                          [3.3351e-04, 3.3351e-04, 3.3351e-04,  ..., 3.2617e-04,\n",
       "                           3.2617e-04, 3.2617e-04],\n",
       "                          [3.3351e-04, 3.3351e-04, 3.3351e-04,  ..., 3.2617e-04,\n",
       "                           3.2617e-04, 3.2617e-04],\n",
       "                          [3.3351e-04, 3.3351e-04, 3.3351e-04,  ..., 3.2617e-04,\n",
       "                           3.2617e-04, 3.2617e-04]]], device='cuda:0')\n",
       "         ) at 0x1ceff8683a0>\n",
       " ) at 0x1cf07191cd0>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf.predict(imgs[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cce61714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\09_Gr2T4_1s_10r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\09_Gr2T4_1s_11r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\09_Gr2T4_1s_12r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\09_Gr2T4_1s_13r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\09_Gr2T4_1s_14r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\09_Gr2T4_1s_15r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\09_Gr2T4_1s_16r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\09_Gr2T4_1s_19r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\09_Gr2T4_1s_1r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\09_Gr2T4_1s_23r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\09_Gr2T4_1s_24r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\09_Gr2T4_1s_26r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\09_Gr2T4_1s_27r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\09_Gr2T4_1s_28r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\09_Gr2T4_1s_29r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\09_Gr2T4_1s_2r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\09_Gr2T4_1s_30r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\09_Gr2T4_1s_31r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\09_Gr2T4_1s_32r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\09_Gr2T4_1s_33r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\09_Gr2T4_1s_34r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\09_Gr2T4_1s_4r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\09_Gr2T4_1s_5r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\09_Gr2T4_1s_6r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\09_Gr2T4_1s_7r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\09_Gr2T4_1s_8r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\09_Gr2T4_1s_9r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\10_Gr2T5_1s_10r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\10_Gr2T5_1s_11r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\10_Gr2T5_1s_11r_0x_4088y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\10_Gr2T5_1s_12r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\10_Gr2T5_1s_13r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\10_Gr2T5_1s_14r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\10_Gr2T5_1s_15r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\10_Gr2T5_1s_16r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\10_Gr2T5_1s_17r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\10_Gr2T5_1s_18r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\10_Gr2T5_1s_19r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\10_Gr2T5_1s_1r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\10_Gr2T5_1s_20r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\10_Gr2T5_1s_21r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\10_Gr2T5_1s_22r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\10_Gr2T5_1s_2r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\10_Gr2T5_1s_3r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\10_Gr2T5_1s_4r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\10_Gr2T5_1s_5r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\10_Gr2T5_1s_6r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\10_Gr2T5_1s_7r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\10_Gr2T5_1s_7r_0x_4088y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\10_Gr2T5_1s_8r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\10_Gr2T5_1s_9r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\11_Gr5T1_1s_0r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\11_Gr5T1_1s_10r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\11_Gr5T1_1s_11r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\11_Gr5T1_1s_12r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\11_Gr5T1_1s_13r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\11_Gr5T1_1s_14r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\11_Gr5T1_1s_15r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\11_Gr5T1_1s_16r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\11_Gr5T1_1s_17r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\11_Gr5T1_1s_18r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\11_Gr5T1_1s_19r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\11_Gr5T1_1s_1r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\11_Gr5T1_1s_20r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\11_Gr5T1_1s_21r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\11_Gr5T1_1s_22r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\11_Gr5T1_1s_23r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\11_Gr5T1_1s_25r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\11_Gr5T1_1s_26r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\11_Gr5T1_1s_27r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\11_Gr5T1_1s_28r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\11_Gr5T1_1s_29r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\11_Gr5T1_1s_2r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\11_Gr5T1_1s_30r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\11_Gr5T1_1s_31r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\11_Gr5T1_1s_33r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\11_Gr5T1_1s_3r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\11_Gr5T1_1s_4r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\11_Gr5T1_1s_5r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\11_Gr5T1_1s_6r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\11_Gr5T1_1s_8r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\11_Gr5T1_1s_9r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_0r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_10r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_11r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_12r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_14r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_15r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_17r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_18r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_19r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_1r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_20r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_21r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_22r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_23r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_24r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_25r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_26r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_27r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_28r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_29r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_2r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_31r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_32r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_33r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_34r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_35r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_36r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_38r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_39r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_3r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_40r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_41r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_42r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_43r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_45r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_46r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_47r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_48r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_49r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_4r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_50r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_51r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_52r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_53r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_54r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_55r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_56r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_58r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_5r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_60r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_61r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_62r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_63r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_64r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_65r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_67r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_68r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_69r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_6r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_72r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_73r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_74r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_75r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_76r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_7r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_8r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\13_Gr5T5_1s_9r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\15_Gr5T7_1s_0r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\15_Gr5T7_1s_0r_0x_4088y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\15_Gr5T7_1s_0r_0x_8176y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\15_Gr5T7_1s_0r_12264x_12264y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\15_Gr5T7_1s_0r_12264x_8176y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\15_Gr5T7_1s_0r_16352x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\15_Gr5T7_1s_0r_16352x_12264y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\15_Gr5T7_1s_0r_16352x_4088y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\15_Gr5T7_1s_0r_16352x_8176y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\15_Gr5T7_1s_0r_4088x_4088y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\15_Gr5T7_1s_0r_4088x_8176y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\15_Gr5T7_1s_0r_8176x_4088y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\15_Gr5T7_1s_0r_8176x_8176y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\17_Gr6T2_1s_0r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\17_Gr6T2_1s_10r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\17_Gr6T2_1s_11r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\17_Gr6T2_1s_12r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\17_Gr6T2_1s_13r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\17_Gr6T2_1s_14r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\17_Gr6T2_1s_15r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\17_Gr6T2_1s_16r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\17_Gr6T2_1s_17r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\17_Gr6T2_1s_18r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\17_Gr6T2_1s_19r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\17_Gr6T2_1s_1r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\17_Gr6T2_1s_20r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\17_Gr6T2_1s_21r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\17_Gr6T2_1s_22r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\17_Gr6T2_1s_23r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\17_Gr6T2_1s_24r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\17_Gr6T2_1s_25r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\17_Gr6T2_1s_26r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\17_Gr6T2_1s_27r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\17_Gr6T2_1s_28r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\17_Gr6T2_1s_29r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\17_Gr6T2_1s_2r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\17_Gr6T2_1s_3r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\17_Gr6T2_1s_5r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\17_Gr6T2_1s_6r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\17_Gr6T2_1s_7r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\17_Gr6T2_1s_8r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\17_Gr6T2_1s_9r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\18_Gr6T3_1s_0r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\18_Gr6T3_1s_10r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\18_Gr6T3_1s_10r_4088x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\18_Gr6T3_1s_11r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\18_Gr6T3_1s_12r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\18_Gr6T3_1s_1r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\18_Gr6T3_1s_2r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\18_Gr6T3_1s_3r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\18_Gr6T3_1s_4r_4088x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\18_Gr6T3_1s_5r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\18_Gr6T3_1s_6r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\18_Gr6T3_1s_7r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\18_Gr6T3_1s_8r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\18_Gr6T3_1s_9r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\18_Gr6T3_1s_9r_4088x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\19_Gr6T4_1s_0r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\19_Gr6T4_1s_0r_4088x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\19_Gr6T4_1s_0r_4088x_4088y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\19_Gr6T4_1s_10r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\19_Gr6T4_1s_11r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\19_Gr6T4_1s_12r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\19_Gr6T4_1s_1r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\19_Gr6T4_1s_2r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\19_Gr6T4_1s_2r_0x_4088y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\19_Gr6T4_1s_2r_4088x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\19_Gr6T4_1s_2r_4088x_4088y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\19_Gr6T4_1s_3r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\19_Gr6T4_1s_4r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\19_Gr6T4_1s_4r_0x_4088y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\19_Gr6T4_1s_5r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\19_Gr6T4_1s_7r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\19_Gr6T4_1s_8r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\20_Gr6T5_1s_0r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\20_Gr6T5_1s_10r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\20_Gr6T5_1s_11r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\20_Gr6T5_1s_12r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\20_Gr6T5_1s_12r_0x_4088y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\20_Gr6T5_1s_13r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\20_Gr6T5_1s_13r_0x_4088y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\20_Gr6T5_1s_15r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\20_Gr6T5_1s_16r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\20_Gr6T5_1s_17r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\20_Gr6T5_1s_18r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\20_Gr6T5_1s_19r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\20_Gr6T5_1s_1r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\20_Gr6T5_1s_2r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\20_Gr6T5_1s_3r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\20_Gr6T5_1s_4r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\20_Gr6T5_1s_5r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\20_Gr6T5_1s_6r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\20_Gr6T5_1s_7r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\20_Gr6T5_1s_8r_0x_0y_.png',\n",
       " 'C:\\\\HSA\\\\HSA-Data\\\\projects\\\\d55090aa-a315-4ae3-8242-b50e13e355f6\\\\dataset\\\\train2017\\\\20_Gr6T5_1s_9r_0x_0y_.png']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c2d48ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: C:\\Users\\philmarq\\source\\repos\\MMWrapperRepo\\firstapitest\\best_coco_bbox_mAP_epoch_25.pth\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: panoptic_head.pixel_decoder.input_convs.0.conv.weight, panoptic_head.pixel_decoder.input_convs.0.conv.bias, panoptic_head.pixel_decoder.input_convs.0.gn.weight, panoptic_head.pixel_decoder.input_convs.0.gn.bias, panoptic_head.pixel_decoder.input_convs.1.conv.weight, panoptic_head.pixel_decoder.input_convs.1.conv.bias, panoptic_head.pixel_decoder.input_convs.1.gn.weight, panoptic_head.pixel_decoder.input_convs.1.gn.bias, panoptic_head.pixel_decoder.input_convs.2.conv.weight, panoptic_head.pixel_decoder.input_convs.2.conv.bias, panoptic_head.pixel_decoder.input_convs.2.gn.weight, panoptic_head.pixel_decoder.input_convs.2.gn.bias, panoptic_head.pixel_decoder.encoder.layers.0.self_attn.sampling_offsets.weight, panoptic_head.pixel_decoder.encoder.layers.0.self_attn.sampling_offsets.bias, panoptic_head.pixel_decoder.encoder.layers.0.self_attn.attention_weights.weight, panoptic_head.pixel_decoder.encoder.layers.0.self_attn.attention_weights.bias, panoptic_head.pixel_decoder.encoder.layers.0.self_attn.value_proj.weight, panoptic_head.pixel_decoder.encoder.layers.0.self_attn.value_proj.bias, panoptic_head.pixel_decoder.encoder.layers.0.self_attn.output_proj.weight, panoptic_head.pixel_decoder.encoder.layers.0.self_attn.output_proj.bias, panoptic_head.pixel_decoder.encoder.layers.0.ffn.layers.0.0.weight, panoptic_head.pixel_decoder.encoder.layers.0.ffn.layers.0.0.bias, panoptic_head.pixel_decoder.encoder.layers.0.ffn.layers.1.weight, panoptic_head.pixel_decoder.encoder.layers.0.ffn.layers.1.bias, panoptic_head.pixel_decoder.encoder.layers.0.norms.0.weight, panoptic_head.pixel_decoder.encoder.layers.0.norms.0.bias, panoptic_head.pixel_decoder.encoder.layers.0.norms.1.weight, panoptic_head.pixel_decoder.encoder.layers.0.norms.1.bias, panoptic_head.pixel_decoder.encoder.layers.1.self_attn.sampling_offsets.weight, panoptic_head.pixel_decoder.encoder.layers.1.self_attn.sampling_offsets.bias, panoptic_head.pixel_decoder.encoder.layers.1.self_attn.attention_weights.weight, panoptic_head.pixel_decoder.encoder.layers.1.self_attn.attention_weights.bias, panoptic_head.pixel_decoder.encoder.layers.1.self_attn.value_proj.weight, panoptic_head.pixel_decoder.encoder.layers.1.self_attn.value_proj.bias, panoptic_head.pixel_decoder.encoder.layers.1.self_attn.output_proj.weight, panoptic_head.pixel_decoder.encoder.layers.1.self_attn.output_proj.bias, panoptic_head.pixel_decoder.encoder.layers.1.ffn.layers.0.0.weight, panoptic_head.pixel_decoder.encoder.layers.1.ffn.layers.0.0.bias, panoptic_head.pixel_decoder.encoder.layers.1.ffn.layers.1.weight, panoptic_head.pixel_decoder.encoder.layers.1.ffn.layers.1.bias, panoptic_head.pixel_decoder.encoder.layers.1.norms.0.weight, panoptic_head.pixel_decoder.encoder.layers.1.norms.0.bias, panoptic_head.pixel_decoder.encoder.layers.1.norms.1.weight, panoptic_head.pixel_decoder.encoder.layers.1.norms.1.bias, panoptic_head.pixel_decoder.encoder.layers.2.self_attn.sampling_offsets.weight, panoptic_head.pixel_decoder.encoder.layers.2.self_attn.sampling_offsets.bias, panoptic_head.pixel_decoder.encoder.layers.2.self_attn.attention_weights.weight, panoptic_head.pixel_decoder.encoder.layers.2.self_attn.attention_weights.bias, panoptic_head.pixel_decoder.encoder.layers.2.self_attn.value_proj.weight, panoptic_head.pixel_decoder.encoder.layers.2.self_attn.value_proj.bias, panoptic_head.pixel_decoder.encoder.layers.2.self_attn.output_proj.weight, panoptic_head.pixel_decoder.encoder.layers.2.self_attn.output_proj.bias, panoptic_head.pixel_decoder.encoder.layers.2.ffn.layers.0.0.weight, panoptic_head.pixel_decoder.encoder.layers.2.ffn.layers.0.0.bias, panoptic_head.pixel_decoder.encoder.layers.2.ffn.layers.1.weight, panoptic_head.pixel_decoder.encoder.layers.2.ffn.layers.1.bias, panoptic_head.pixel_decoder.encoder.layers.2.norms.0.weight, panoptic_head.pixel_decoder.encoder.layers.2.norms.0.bias, panoptic_head.pixel_decoder.encoder.layers.2.norms.1.weight, panoptic_head.pixel_decoder.encoder.layers.2.norms.1.bias, panoptic_head.pixel_decoder.encoder.layers.3.self_attn.sampling_offsets.weight, panoptic_head.pixel_decoder.encoder.layers.3.self_attn.sampling_offsets.bias, panoptic_head.pixel_decoder.encoder.layers.3.self_attn.attention_weights.weight, panoptic_head.pixel_decoder.encoder.layers.3.self_attn.attention_weights.bias, panoptic_head.pixel_decoder.encoder.layers.3.self_attn.value_proj.weight, panoptic_head.pixel_decoder.encoder.layers.3.self_attn.value_proj.bias, panoptic_head.pixel_decoder.encoder.layers.3.self_attn.output_proj.weight, panoptic_head.pixel_decoder.encoder.layers.3.self_attn.output_proj.bias, panoptic_head.pixel_decoder.encoder.layers.3.ffn.layers.0.0.weight, panoptic_head.pixel_decoder.encoder.layers.3.ffn.layers.0.0.bias, panoptic_head.pixel_decoder.encoder.layers.3.ffn.layers.1.weight, panoptic_head.pixel_decoder.encoder.layers.3.ffn.layers.1.bias, panoptic_head.pixel_decoder.encoder.layers.3.norms.0.weight, panoptic_head.pixel_decoder.encoder.layers.3.norms.0.bias, panoptic_head.pixel_decoder.encoder.layers.3.norms.1.weight, panoptic_head.pixel_decoder.encoder.layers.3.norms.1.bias, panoptic_head.pixel_decoder.encoder.layers.4.self_attn.sampling_offsets.weight, panoptic_head.pixel_decoder.encoder.layers.4.self_attn.sampling_offsets.bias, panoptic_head.pixel_decoder.encoder.layers.4.self_attn.attention_weights.weight, panoptic_head.pixel_decoder.encoder.layers.4.self_attn.attention_weights.bias, panoptic_head.pixel_decoder.encoder.layers.4.self_attn.value_proj.weight, panoptic_head.pixel_decoder.encoder.layers.4.self_attn.value_proj.bias, panoptic_head.pixel_decoder.encoder.layers.4.self_attn.output_proj.weight, panoptic_head.pixel_decoder.encoder.layers.4.self_attn.output_proj.bias, panoptic_head.pixel_decoder.encoder.layers.4.ffn.layers.0.0.weight, panoptic_head.pixel_decoder.encoder.layers.4.ffn.layers.0.0.bias, panoptic_head.pixel_decoder.encoder.layers.4.ffn.layers.1.weight, panoptic_head.pixel_decoder.encoder.layers.4.ffn.layers.1.bias, panoptic_head.pixel_decoder.encoder.layers.4.norms.0.weight, panoptic_head.pixel_decoder.encoder.layers.4.norms.0.bias, panoptic_head.pixel_decoder.encoder.layers.4.norms.1.weight, panoptic_head.pixel_decoder.encoder.layers.4.norms.1.bias, panoptic_head.pixel_decoder.encoder.layers.5.self_attn.sampling_offsets.weight, panoptic_head.pixel_decoder.encoder.layers.5.self_attn.sampling_offsets.bias, panoptic_head.pixel_decoder.encoder.layers.5.self_attn.attention_weights.weight, panoptic_head.pixel_decoder.encoder.layers.5.self_attn.attention_weights.bias, panoptic_head.pixel_decoder.encoder.layers.5.self_attn.value_proj.weight, panoptic_head.pixel_decoder.encoder.layers.5.self_attn.value_proj.bias, panoptic_head.pixel_decoder.encoder.layers.5.self_attn.output_proj.weight, panoptic_head.pixel_decoder.encoder.layers.5.self_attn.output_proj.bias, panoptic_head.pixel_decoder.encoder.layers.5.ffn.layers.0.0.weight, panoptic_head.pixel_decoder.encoder.layers.5.ffn.layers.0.0.bias, panoptic_head.pixel_decoder.encoder.layers.5.ffn.layers.1.weight, panoptic_head.pixel_decoder.encoder.layers.5.ffn.layers.1.bias, panoptic_head.pixel_decoder.encoder.layers.5.norms.0.weight, panoptic_head.pixel_decoder.encoder.layers.5.norms.0.bias, panoptic_head.pixel_decoder.encoder.layers.5.norms.1.weight, panoptic_head.pixel_decoder.encoder.layers.5.norms.1.bias, panoptic_head.pixel_decoder.level_encoding.weight, panoptic_head.pixel_decoder.lateral_convs.0.conv.weight, panoptic_head.pixel_decoder.lateral_convs.0.gn.weight, panoptic_head.pixel_decoder.lateral_convs.0.gn.bias, panoptic_head.pixel_decoder.output_convs.0.conv.weight, panoptic_head.pixel_decoder.output_convs.0.gn.weight, panoptic_head.pixel_decoder.output_convs.0.gn.bias, panoptic_head.pixel_decoder.mask_feature.weight, panoptic_head.pixel_decoder.mask_feature.bias, panoptic_head.transformer_decoder.layers.0.self_attn.attn.in_proj_weight, panoptic_head.transformer_decoder.layers.0.self_attn.attn.in_proj_bias, panoptic_head.transformer_decoder.layers.0.self_attn.attn.out_proj.weight, panoptic_head.transformer_decoder.layers.0.self_attn.attn.out_proj.bias, panoptic_head.transformer_decoder.layers.0.cross_attn.attn.in_proj_weight, panoptic_head.transformer_decoder.layers.0.cross_attn.attn.in_proj_bias, panoptic_head.transformer_decoder.layers.0.cross_attn.attn.out_proj.weight, panoptic_head.transformer_decoder.layers.0.cross_attn.attn.out_proj.bias, panoptic_head.transformer_decoder.layers.0.ffn.layers.0.0.weight, panoptic_head.transformer_decoder.layers.0.ffn.layers.0.0.bias, panoptic_head.transformer_decoder.layers.0.ffn.layers.1.weight, panoptic_head.transformer_decoder.layers.0.ffn.layers.1.bias, panoptic_head.transformer_decoder.layers.0.norms.0.weight, panoptic_head.transformer_decoder.layers.0.norms.0.bias, panoptic_head.transformer_decoder.layers.0.norms.1.weight, panoptic_head.transformer_decoder.layers.0.norms.1.bias, panoptic_head.transformer_decoder.layers.0.norms.2.weight, panoptic_head.transformer_decoder.layers.0.norms.2.bias, panoptic_head.transformer_decoder.layers.1.self_attn.attn.in_proj_weight, panoptic_head.transformer_decoder.layers.1.self_attn.attn.in_proj_bias, panoptic_head.transformer_decoder.layers.1.self_attn.attn.out_proj.weight, panoptic_head.transformer_decoder.layers.1.self_attn.attn.out_proj.bias, panoptic_head.transformer_decoder.layers.1.cross_attn.attn.in_proj_weight, panoptic_head.transformer_decoder.layers.1.cross_attn.attn.in_proj_bias, panoptic_head.transformer_decoder.layers.1.cross_attn.attn.out_proj.weight, panoptic_head.transformer_decoder.layers.1.cross_attn.attn.out_proj.bias, panoptic_head.transformer_decoder.layers.1.ffn.layers.0.0.weight, panoptic_head.transformer_decoder.layers.1.ffn.layers.0.0.bias, panoptic_head.transformer_decoder.layers.1.ffn.layers.1.weight, panoptic_head.transformer_decoder.layers.1.ffn.layers.1.bias, panoptic_head.transformer_decoder.layers.1.norms.0.weight, panoptic_head.transformer_decoder.layers.1.norms.0.bias, panoptic_head.transformer_decoder.layers.1.norms.1.weight, panoptic_head.transformer_decoder.layers.1.norms.1.bias, panoptic_head.transformer_decoder.layers.1.norms.2.weight, panoptic_head.transformer_decoder.layers.1.norms.2.bias, panoptic_head.transformer_decoder.layers.2.self_attn.attn.in_proj_weight, panoptic_head.transformer_decoder.layers.2.self_attn.attn.in_proj_bias, panoptic_head.transformer_decoder.layers.2.self_attn.attn.out_proj.weight, panoptic_head.transformer_decoder.layers.2.self_attn.attn.out_proj.bias, panoptic_head.transformer_decoder.layers.2.cross_attn.attn.in_proj_weight, panoptic_head.transformer_decoder.layers.2.cross_attn.attn.in_proj_bias, panoptic_head.transformer_decoder.layers.2.cross_attn.attn.out_proj.weight, panoptic_head.transformer_decoder.layers.2.cross_attn.attn.out_proj.bias, panoptic_head.transformer_decoder.layers.2.ffn.layers.0.0.weight, panoptic_head.transformer_decoder.layers.2.ffn.layers.0.0.bias, panoptic_head.transformer_decoder.layers.2.ffn.layers.1.weight, panoptic_head.transformer_decoder.layers.2.ffn.layers.1.bias, panoptic_head.transformer_decoder.layers.2.norms.0.weight, panoptic_head.transformer_decoder.layers.2.norms.0.bias, panoptic_head.transformer_decoder.layers.2.norms.1.weight, panoptic_head.transformer_decoder.layers.2.norms.1.bias, panoptic_head.transformer_decoder.layers.2.norms.2.weight, panoptic_head.transformer_decoder.layers.2.norms.2.bias, panoptic_head.transformer_decoder.layers.3.self_attn.attn.in_proj_weight, panoptic_head.transformer_decoder.layers.3.self_attn.attn.in_proj_bias, panoptic_head.transformer_decoder.layers.3.self_attn.attn.out_proj.weight, panoptic_head.transformer_decoder.layers.3.self_attn.attn.out_proj.bias, panoptic_head.transformer_decoder.layers.3.cross_attn.attn.in_proj_weight, panoptic_head.transformer_decoder.layers.3.cross_attn.attn.in_proj_bias, panoptic_head.transformer_decoder.layers.3.cross_attn.attn.out_proj.weight, panoptic_head.transformer_decoder.layers.3.cross_attn.attn.out_proj.bias, panoptic_head.transformer_decoder.layers.3.ffn.layers.0.0.weight, panoptic_head.transformer_decoder.layers.3.ffn.layers.0.0.bias, panoptic_head.transformer_decoder.layers.3.ffn.layers.1.weight, panoptic_head.transformer_decoder.layers.3.ffn.layers.1.bias, panoptic_head.transformer_decoder.layers.3.norms.0.weight, panoptic_head.transformer_decoder.layers.3.norms.0.bias, panoptic_head.transformer_decoder.layers.3.norms.1.weight, panoptic_head.transformer_decoder.layers.3.norms.1.bias, panoptic_head.transformer_decoder.layers.3.norms.2.weight, panoptic_head.transformer_decoder.layers.3.norms.2.bias, panoptic_head.transformer_decoder.layers.4.self_attn.attn.in_proj_weight, panoptic_head.transformer_decoder.layers.4.self_attn.attn.in_proj_bias, panoptic_head.transformer_decoder.layers.4.self_attn.attn.out_proj.weight, panoptic_head.transformer_decoder.layers.4.self_attn.attn.out_proj.bias, panoptic_head.transformer_decoder.layers.4.cross_attn.attn.in_proj_weight, panoptic_head.transformer_decoder.layers.4.cross_attn.attn.in_proj_bias, panoptic_head.transformer_decoder.layers.4.cross_attn.attn.out_proj.weight, panoptic_head.transformer_decoder.layers.4.cross_attn.attn.out_proj.bias, panoptic_head.transformer_decoder.layers.4.ffn.layers.0.0.weight, panoptic_head.transformer_decoder.layers.4.ffn.layers.0.0.bias, panoptic_head.transformer_decoder.layers.4.ffn.layers.1.weight, panoptic_head.transformer_decoder.layers.4.ffn.layers.1.bias, panoptic_head.transformer_decoder.layers.4.norms.0.weight, panoptic_head.transformer_decoder.layers.4.norms.0.bias, panoptic_head.transformer_decoder.layers.4.norms.1.weight, panoptic_head.transformer_decoder.layers.4.norms.1.bias, panoptic_head.transformer_decoder.layers.4.norms.2.weight, panoptic_head.transformer_decoder.layers.4.norms.2.bias, panoptic_head.transformer_decoder.layers.5.self_attn.attn.in_proj_weight, panoptic_head.transformer_decoder.layers.5.self_attn.attn.in_proj_bias, panoptic_head.transformer_decoder.layers.5.self_attn.attn.out_proj.weight, panoptic_head.transformer_decoder.layers.5.self_attn.attn.out_proj.bias, panoptic_head.transformer_decoder.layers.5.cross_attn.attn.in_proj_weight, panoptic_head.transformer_decoder.layers.5.cross_attn.attn.in_proj_bias, panoptic_head.transformer_decoder.layers.5.cross_attn.attn.out_proj.weight, panoptic_head.transformer_decoder.layers.5.cross_attn.attn.out_proj.bias, panoptic_head.transformer_decoder.layers.5.ffn.layers.0.0.weight, panoptic_head.transformer_decoder.layers.5.ffn.layers.0.0.bias, panoptic_head.transformer_decoder.layers.5.ffn.layers.1.weight, panoptic_head.transformer_decoder.layers.5.ffn.layers.1.bias, panoptic_head.transformer_decoder.layers.5.norms.0.weight, panoptic_head.transformer_decoder.layers.5.norms.0.bias, panoptic_head.transformer_decoder.layers.5.norms.1.weight, panoptic_head.transformer_decoder.layers.5.norms.1.bias, panoptic_head.transformer_decoder.layers.5.norms.2.weight, panoptic_head.transformer_decoder.layers.5.norms.2.bias, panoptic_head.transformer_decoder.layers.6.self_attn.attn.in_proj_weight, panoptic_head.transformer_decoder.layers.6.self_attn.attn.in_proj_bias, panoptic_head.transformer_decoder.layers.6.self_attn.attn.out_proj.weight, panoptic_head.transformer_decoder.layers.6.self_attn.attn.out_proj.bias, panoptic_head.transformer_decoder.layers.6.cross_attn.attn.in_proj_weight, panoptic_head.transformer_decoder.layers.6.cross_attn.attn.in_proj_bias, panoptic_head.transformer_decoder.layers.6.cross_attn.attn.out_proj.weight, panoptic_head.transformer_decoder.layers.6.cross_attn.attn.out_proj.bias, panoptic_head.transformer_decoder.layers.6.ffn.layers.0.0.weight, panoptic_head.transformer_decoder.layers.6.ffn.layers.0.0.bias, panoptic_head.transformer_decoder.layers.6.ffn.layers.1.weight, panoptic_head.transformer_decoder.layers.6.ffn.layers.1.bias, panoptic_head.transformer_decoder.layers.6.norms.0.weight, panoptic_head.transformer_decoder.layers.6.norms.0.bias, panoptic_head.transformer_decoder.layers.6.norms.1.weight, panoptic_head.transformer_decoder.layers.6.norms.1.bias, panoptic_head.transformer_decoder.layers.6.norms.2.weight, panoptic_head.transformer_decoder.layers.6.norms.2.bias, panoptic_head.transformer_decoder.layers.7.self_attn.attn.in_proj_weight, panoptic_head.transformer_decoder.layers.7.self_attn.attn.in_proj_bias, panoptic_head.transformer_decoder.layers.7.self_attn.attn.out_proj.weight, panoptic_head.transformer_decoder.layers.7.self_attn.attn.out_proj.bias, panoptic_head.transformer_decoder.layers.7.cross_attn.attn.in_proj_weight, panoptic_head.transformer_decoder.layers.7.cross_attn.attn.in_proj_bias, panoptic_head.transformer_decoder.layers.7.cross_attn.attn.out_proj.weight, panoptic_head.transformer_decoder.layers.7.cross_attn.attn.out_proj.bias, panoptic_head.transformer_decoder.layers.7.ffn.layers.0.0.weight, panoptic_head.transformer_decoder.layers.7.ffn.layers.0.0.bias, panoptic_head.transformer_decoder.layers.7.ffn.layers.1.weight, panoptic_head.transformer_decoder.layers.7.ffn.layers.1.bias, panoptic_head.transformer_decoder.layers.7.norms.0.weight, panoptic_head.transformer_decoder.layers.7.norms.0.bias, panoptic_head.transformer_decoder.layers.7.norms.1.weight, panoptic_head.transformer_decoder.layers.7.norms.1.bias, panoptic_head.transformer_decoder.layers.7.norms.2.weight, panoptic_head.transformer_decoder.layers.7.norms.2.bias, panoptic_head.transformer_decoder.layers.8.self_attn.attn.in_proj_weight, panoptic_head.transformer_decoder.layers.8.self_attn.attn.in_proj_bias, panoptic_head.transformer_decoder.layers.8.self_attn.attn.out_proj.weight, panoptic_head.transformer_decoder.layers.8.self_attn.attn.out_proj.bias, panoptic_head.transformer_decoder.layers.8.cross_attn.attn.in_proj_weight, panoptic_head.transformer_decoder.layers.8.cross_attn.attn.in_proj_bias, panoptic_head.transformer_decoder.layers.8.cross_attn.attn.out_proj.weight, panoptic_head.transformer_decoder.layers.8.cross_attn.attn.out_proj.bias, panoptic_head.transformer_decoder.layers.8.ffn.layers.0.0.weight, panoptic_head.transformer_decoder.layers.8.ffn.layers.0.0.bias, panoptic_head.transformer_decoder.layers.8.ffn.layers.1.weight, panoptic_head.transformer_decoder.layers.8.ffn.layers.1.bias, panoptic_head.transformer_decoder.layers.8.norms.0.weight, panoptic_head.transformer_decoder.layers.8.norms.0.bias, panoptic_head.transformer_decoder.layers.8.norms.1.weight, panoptic_head.transformer_decoder.layers.8.norms.1.bias, panoptic_head.transformer_decoder.layers.8.norms.2.weight, panoptic_head.transformer_decoder.layers.8.norms.2.bias, panoptic_head.transformer_decoder.post_norm.weight, panoptic_head.transformer_decoder.post_norm.bias, panoptic_head.query_embed.weight, panoptic_head.query_feat.weight, panoptic_head.level_embed.weight, panoptic_head.cls_embed.weight, panoptic_head.cls_embed.bias, panoptic_head.mask_embed.0.weight, panoptic_head.mask_embed.0.bias, panoptic_head.mask_embed.2.weight, panoptic_head.mask_embed.2.bias, panoptic_head.mask_embed.4.weight, panoptic_head.mask_embed.4.bias, backbone.patch_embed.projection.weight, backbone.patch_embed.projection.bias, backbone.patch_embed.norm.weight, backbone.patch_embed.norm.bias, backbone.stages.0.blocks.0.norm1.weight, backbone.stages.0.blocks.0.norm1.bias, backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table, backbone.stages.0.blocks.0.attn.w_msa.relative_position_index, backbone.stages.0.blocks.0.attn.w_msa.qkv.weight, backbone.stages.0.blocks.0.attn.w_msa.qkv.bias, backbone.stages.0.blocks.0.attn.w_msa.proj.weight, backbone.stages.0.blocks.0.attn.w_msa.proj.bias, backbone.stages.0.blocks.0.norm2.weight, backbone.stages.0.blocks.0.norm2.bias, backbone.stages.0.blocks.0.ffn.layers.0.0.weight, backbone.stages.0.blocks.0.ffn.layers.0.0.bias, backbone.stages.0.blocks.0.ffn.layers.1.weight, backbone.stages.0.blocks.0.ffn.layers.1.bias, backbone.stages.0.blocks.1.norm1.weight, backbone.stages.0.blocks.1.norm1.bias, backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table, backbone.stages.0.blocks.1.attn.w_msa.relative_position_index, backbone.stages.0.blocks.1.attn.w_msa.qkv.weight, backbone.stages.0.blocks.1.attn.w_msa.qkv.bias, backbone.stages.0.blocks.1.attn.w_msa.proj.weight, backbone.stages.0.blocks.1.attn.w_msa.proj.bias, backbone.stages.0.blocks.1.norm2.weight, backbone.stages.0.blocks.1.norm2.bias, backbone.stages.0.blocks.1.ffn.layers.0.0.weight, backbone.stages.0.blocks.1.ffn.layers.0.0.bias, backbone.stages.0.blocks.1.ffn.layers.1.weight, backbone.stages.0.blocks.1.ffn.layers.1.bias, backbone.stages.0.downsample.norm.weight, backbone.stages.0.downsample.norm.bias, backbone.stages.0.downsample.reduction.weight, backbone.stages.1.blocks.0.norm1.weight, backbone.stages.1.blocks.0.norm1.bias, backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table, backbone.stages.1.blocks.0.attn.w_msa.relative_position_index, backbone.stages.1.blocks.0.attn.w_msa.qkv.weight, backbone.stages.1.blocks.0.attn.w_msa.qkv.bias, backbone.stages.1.blocks.0.attn.w_msa.proj.weight, backbone.stages.1.blocks.0.attn.w_msa.proj.bias, backbone.stages.1.blocks.0.norm2.weight, backbone.stages.1.blocks.0.norm2.bias, backbone.stages.1.blocks.0.ffn.layers.0.0.weight, backbone.stages.1.blocks.0.ffn.layers.0.0.bias, backbone.stages.1.blocks.0.ffn.layers.1.weight, backbone.stages.1.blocks.0.ffn.layers.1.bias, backbone.stages.1.blocks.1.norm1.weight, backbone.stages.1.blocks.1.norm1.bias, backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table, backbone.stages.1.blocks.1.attn.w_msa.relative_position_index, backbone.stages.1.blocks.1.attn.w_msa.qkv.weight, backbone.stages.1.blocks.1.attn.w_msa.qkv.bias, backbone.stages.1.blocks.1.attn.w_msa.proj.weight, backbone.stages.1.blocks.1.attn.w_msa.proj.bias, backbone.stages.1.blocks.1.norm2.weight, backbone.stages.1.blocks.1.norm2.bias, backbone.stages.1.blocks.1.ffn.layers.0.0.weight, backbone.stages.1.blocks.1.ffn.layers.0.0.bias, backbone.stages.1.blocks.1.ffn.layers.1.weight, backbone.stages.1.blocks.1.ffn.layers.1.bias, backbone.stages.1.downsample.norm.weight, backbone.stages.1.downsample.norm.bias, backbone.stages.1.downsample.reduction.weight, backbone.stages.2.blocks.0.norm1.weight, backbone.stages.2.blocks.0.norm1.bias, backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.0.attn.w_msa.relative_position_index, backbone.stages.2.blocks.0.attn.w_msa.qkv.weight, backbone.stages.2.blocks.0.attn.w_msa.qkv.bias, backbone.stages.2.blocks.0.attn.w_msa.proj.weight, backbone.stages.2.blocks.0.attn.w_msa.proj.bias, backbone.stages.2.blocks.0.norm2.weight, backbone.stages.2.blocks.0.norm2.bias, backbone.stages.2.blocks.0.ffn.layers.0.0.weight, backbone.stages.2.blocks.0.ffn.layers.0.0.bias, backbone.stages.2.blocks.0.ffn.layers.1.weight, backbone.stages.2.blocks.0.ffn.layers.1.bias, backbone.stages.2.blocks.1.norm1.weight, backbone.stages.2.blocks.1.norm1.bias, backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.1.attn.w_msa.relative_position_index, backbone.stages.2.blocks.1.attn.w_msa.qkv.weight, backbone.stages.2.blocks.1.attn.w_msa.qkv.bias, backbone.stages.2.blocks.1.attn.w_msa.proj.weight, backbone.stages.2.blocks.1.attn.w_msa.proj.bias, backbone.stages.2.blocks.1.norm2.weight, backbone.stages.2.blocks.1.norm2.bias, backbone.stages.2.blocks.1.ffn.layers.0.0.weight, backbone.stages.2.blocks.1.ffn.layers.0.0.bias, backbone.stages.2.blocks.1.ffn.layers.1.weight, backbone.stages.2.blocks.1.ffn.layers.1.bias, backbone.stages.2.blocks.2.norm1.weight, backbone.stages.2.blocks.2.norm1.bias, backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.2.attn.w_msa.relative_position_index, backbone.stages.2.blocks.2.attn.w_msa.qkv.weight, backbone.stages.2.blocks.2.attn.w_msa.qkv.bias, backbone.stages.2.blocks.2.attn.w_msa.proj.weight, backbone.stages.2.blocks.2.attn.w_msa.proj.bias, backbone.stages.2.blocks.2.norm2.weight, backbone.stages.2.blocks.2.norm2.bias, backbone.stages.2.blocks.2.ffn.layers.0.0.weight, backbone.stages.2.blocks.2.ffn.layers.0.0.bias, backbone.stages.2.blocks.2.ffn.layers.1.weight, backbone.stages.2.blocks.2.ffn.layers.1.bias, backbone.stages.2.blocks.3.norm1.weight, backbone.stages.2.blocks.3.norm1.bias, backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.3.attn.w_msa.relative_position_index, backbone.stages.2.blocks.3.attn.w_msa.qkv.weight, backbone.stages.2.blocks.3.attn.w_msa.qkv.bias, backbone.stages.2.blocks.3.attn.w_msa.proj.weight, backbone.stages.2.blocks.3.attn.w_msa.proj.bias, backbone.stages.2.blocks.3.norm2.weight, backbone.stages.2.blocks.3.norm2.bias, backbone.stages.2.blocks.3.ffn.layers.0.0.weight, backbone.stages.2.blocks.3.ffn.layers.0.0.bias, backbone.stages.2.blocks.3.ffn.layers.1.weight, backbone.stages.2.blocks.3.ffn.layers.1.bias, backbone.stages.2.blocks.4.norm1.weight, backbone.stages.2.blocks.4.norm1.bias, backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.4.attn.w_msa.relative_position_index, backbone.stages.2.blocks.4.attn.w_msa.qkv.weight, backbone.stages.2.blocks.4.attn.w_msa.qkv.bias, backbone.stages.2.blocks.4.attn.w_msa.proj.weight, backbone.stages.2.blocks.4.attn.w_msa.proj.bias, backbone.stages.2.blocks.4.norm2.weight, backbone.stages.2.blocks.4.norm2.bias, backbone.stages.2.blocks.4.ffn.layers.0.0.weight, backbone.stages.2.blocks.4.ffn.layers.0.0.bias, backbone.stages.2.blocks.4.ffn.layers.1.weight, backbone.stages.2.blocks.4.ffn.layers.1.bias, backbone.stages.2.blocks.5.norm1.weight, backbone.stages.2.blocks.5.norm1.bias, backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.5.attn.w_msa.relative_position_index, backbone.stages.2.blocks.5.attn.w_msa.qkv.weight, backbone.stages.2.blocks.5.attn.w_msa.qkv.bias, backbone.stages.2.blocks.5.attn.w_msa.proj.weight, backbone.stages.2.blocks.5.attn.w_msa.proj.bias, backbone.stages.2.blocks.5.norm2.weight, backbone.stages.2.blocks.5.norm2.bias, backbone.stages.2.blocks.5.ffn.layers.0.0.weight, backbone.stages.2.blocks.5.ffn.layers.0.0.bias, backbone.stages.2.blocks.5.ffn.layers.1.weight, backbone.stages.2.blocks.5.ffn.layers.1.bias, backbone.stages.2.blocks.6.norm1.weight, backbone.stages.2.blocks.6.norm1.bias, backbone.stages.2.blocks.6.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.6.attn.w_msa.relative_position_index, backbone.stages.2.blocks.6.attn.w_msa.qkv.weight, backbone.stages.2.blocks.6.attn.w_msa.qkv.bias, backbone.stages.2.blocks.6.attn.w_msa.proj.weight, backbone.stages.2.blocks.6.attn.w_msa.proj.bias, backbone.stages.2.blocks.6.norm2.weight, backbone.stages.2.blocks.6.norm2.bias, backbone.stages.2.blocks.6.ffn.layers.0.0.weight, backbone.stages.2.blocks.6.ffn.layers.0.0.bias, backbone.stages.2.blocks.6.ffn.layers.1.weight, backbone.stages.2.blocks.6.ffn.layers.1.bias, backbone.stages.2.blocks.7.norm1.weight, backbone.stages.2.blocks.7.norm1.bias, backbone.stages.2.blocks.7.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.7.attn.w_msa.relative_position_index, backbone.stages.2.blocks.7.attn.w_msa.qkv.weight, backbone.stages.2.blocks.7.attn.w_msa.qkv.bias, backbone.stages.2.blocks.7.attn.w_msa.proj.weight, backbone.stages.2.blocks.7.attn.w_msa.proj.bias, backbone.stages.2.blocks.7.norm2.weight, backbone.stages.2.blocks.7.norm2.bias, backbone.stages.2.blocks.7.ffn.layers.0.0.weight, backbone.stages.2.blocks.7.ffn.layers.0.0.bias, backbone.stages.2.blocks.7.ffn.layers.1.weight, backbone.stages.2.blocks.7.ffn.layers.1.bias, backbone.stages.2.blocks.8.norm1.weight, backbone.stages.2.blocks.8.norm1.bias, backbone.stages.2.blocks.8.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.8.attn.w_msa.relative_position_index, backbone.stages.2.blocks.8.attn.w_msa.qkv.weight, backbone.stages.2.blocks.8.attn.w_msa.qkv.bias, backbone.stages.2.blocks.8.attn.w_msa.proj.weight, backbone.stages.2.blocks.8.attn.w_msa.proj.bias, backbone.stages.2.blocks.8.norm2.weight, backbone.stages.2.blocks.8.norm2.bias, backbone.stages.2.blocks.8.ffn.layers.0.0.weight, backbone.stages.2.blocks.8.ffn.layers.0.0.bias, backbone.stages.2.blocks.8.ffn.layers.1.weight, backbone.stages.2.blocks.8.ffn.layers.1.bias, backbone.stages.2.blocks.9.norm1.weight, backbone.stages.2.blocks.9.norm1.bias, backbone.stages.2.blocks.9.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.9.attn.w_msa.relative_position_index, backbone.stages.2.blocks.9.attn.w_msa.qkv.weight, backbone.stages.2.blocks.9.attn.w_msa.qkv.bias, backbone.stages.2.blocks.9.attn.w_msa.proj.weight, backbone.stages.2.blocks.9.attn.w_msa.proj.bias, backbone.stages.2.blocks.9.norm2.weight, backbone.stages.2.blocks.9.norm2.bias, backbone.stages.2.blocks.9.ffn.layers.0.0.weight, backbone.stages.2.blocks.9.ffn.layers.0.0.bias, backbone.stages.2.blocks.9.ffn.layers.1.weight, backbone.stages.2.blocks.9.ffn.layers.1.bias, backbone.stages.2.blocks.10.norm1.weight, backbone.stages.2.blocks.10.norm1.bias, backbone.stages.2.blocks.10.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.10.attn.w_msa.relative_position_index, backbone.stages.2.blocks.10.attn.w_msa.qkv.weight, backbone.stages.2.blocks.10.attn.w_msa.qkv.bias, backbone.stages.2.blocks.10.attn.w_msa.proj.weight, backbone.stages.2.blocks.10.attn.w_msa.proj.bias, backbone.stages.2.blocks.10.norm2.weight, backbone.stages.2.blocks.10.norm2.bias, backbone.stages.2.blocks.10.ffn.layers.0.0.weight, backbone.stages.2.blocks.10.ffn.layers.0.0.bias, backbone.stages.2.blocks.10.ffn.layers.1.weight, backbone.stages.2.blocks.10.ffn.layers.1.bias, backbone.stages.2.blocks.11.norm1.weight, backbone.stages.2.blocks.11.norm1.bias, backbone.stages.2.blocks.11.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.11.attn.w_msa.relative_position_index, backbone.stages.2.blocks.11.attn.w_msa.qkv.weight, backbone.stages.2.blocks.11.attn.w_msa.qkv.bias, backbone.stages.2.blocks.11.attn.w_msa.proj.weight, backbone.stages.2.blocks.11.attn.w_msa.proj.bias, backbone.stages.2.blocks.11.norm2.weight, backbone.stages.2.blocks.11.norm2.bias, backbone.stages.2.blocks.11.ffn.layers.0.0.weight, backbone.stages.2.blocks.11.ffn.layers.0.0.bias, backbone.stages.2.blocks.11.ffn.layers.1.weight, backbone.stages.2.blocks.11.ffn.layers.1.bias, backbone.stages.2.blocks.12.norm1.weight, backbone.stages.2.blocks.12.norm1.bias, backbone.stages.2.blocks.12.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.12.attn.w_msa.relative_position_index, backbone.stages.2.blocks.12.attn.w_msa.qkv.weight, backbone.stages.2.blocks.12.attn.w_msa.qkv.bias, backbone.stages.2.blocks.12.attn.w_msa.proj.weight, backbone.stages.2.blocks.12.attn.w_msa.proj.bias, backbone.stages.2.blocks.12.norm2.weight, backbone.stages.2.blocks.12.norm2.bias, backbone.stages.2.blocks.12.ffn.layers.0.0.weight, backbone.stages.2.blocks.12.ffn.layers.0.0.bias, backbone.stages.2.blocks.12.ffn.layers.1.weight, backbone.stages.2.blocks.12.ffn.layers.1.bias, backbone.stages.2.blocks.13.norm1.weight, backbone.stages.2.blocks.13.norm1.bias, backbone.stages.2.blocks.13.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.13.attn.w_msa.relative_position_index, backbone.stages.2.blocks.13.attn.w_msa.qkv.weight, backbone.stages.2.blocks.13.attn.w_msa.qkv.bias, backbone.stages.2.blocks.13.attn.w_msa.proj.weight, backbone.stages.2.blocks.13.attn.w_msa.proj.bias, backbone.stages.2.blocks.13.norm2.weight, backbone.stages.2.blocks.13.norm2.bias, backbone.stages.2.blocks.13.ffn.layers.0.0.weight, backbone.stages.2.blocks.13.ffn.layers.0.0.bias, backbone.stages.2.blocks.13.ffn.layers.1.weight, backbone.stages.2.blocks.13.ffn.layers.1.bias, backbone.stages.2.blocks.14.norm1.weight, backbone.stages.2.blocks.14.norm1.bias, backbone.stages.2.blocks.14.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.14.attn.w_msa.relative_position_index, backbone.stages.2.blocks.14.attn.w_msa.qkv.weight, backbone.stages.2.blocks.14.attn.w_msa.qkv.bias, backbone.stages.2.blocks.14.attn.w_msa.proj.weight, backbone.stages.2.blocks.14.attn.w_msa.proj.bias, backbone.stages.2.blocks.14.norm2.weight, backbone.stages.2.blocks.14.norm2.bias, backbone.stages.2.blocks.14.ffn.layers.0.0.weight, backbone.stages.2.blocks.14.ffn.layers.0.0.bias, backbone.stages.2.blocks.14.ffn.layers.1.weight, backbone.stages.2.blocks.14.ffn.layers.1.bias, backbone.stages.2.blocks.15.norm1.weight, backbone.stages.2.blocks.15.norm1.bias, backbone.stages.2.blocks.15.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.15.attn.w_msa.relative_position_index, backbone.stages.2.blocks.15.attn.w_msa.qkv.weight, backbone.stages.2.blocks.15.attn.w_msa.qkv.bias, backbone.stages.2.blocks.15.attn.w_msa.proj.weight, backbone.stages.2.blocks.15.attn.w_msa.proj.bias, backbone.stages.2.blocks.15.norm2.weight, backbone.stages.2.blocks.15.norm2.bias, backbone.stages.2.blocks.15.ffn.layers.0.0.weight, backbone.stages.2.blocks.15.ffn.layers.0.0.bias, backbone.stages.2.blocks.15.ffn.layers.1.weight, backbone.stages.2.blocks.15.ffn.layers.1.bias, backbone.stages.2.blocks.16.norm1.weight, backbone.stages.2.blocks.16.norm1.bias, backbone.stages.2.blocks.16.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.16.attn.w_msa.relative_position_index, backbone.stages.2.blocks.16.attn.w_msa.qkv.weight, backbone.stages.2.blocks.16.attn.w_msa.qkv.bias, backbone.stages.2.blocks.16.attn.w_msa.proj.weight, backbone.stages.2.blocks.16.attn.w_msa.proj.bias, backbone.stages.2.blocks.16.norm2.weight, backbone.stages.2.blocks.16.norm2.bias, backbone.stages.2.blocks.16.ffn.layers.0.0.weight, backbone.stages.2.blocks.16.ffn.layers.0.0.bias, backbone.stages.2.blocks.16.ffn.layers.1.weight, backbone.stages.2.blocks.16.ffn.layers.1.bias, backbone.stages.2.blocks.17.norm1.weight, backbone.stages.2.blocks.17.norm1.bias, backbone.stages.2.blocks.17.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.17.attn.w_msa.relative_position_index, backbone.stages.2.blocks.17.attn.w_msa.qkv.weight, backbone.stages.2.blocks.17.attn.w_msa.qkv.bias, backbone.stages.2.blocks.17.attn.w_msa.proj.weight, backbone.stages.2.blocks.17.attn.w_msa.proj.bias, backbone.stages.2.blocks.17.norm2.weight, backbone.stages.2.blocks.17.norm2.bias, backbone.stages.2.blocks.17.ffn.layers.0.0.weight, backbone.stages.2.blocks.17.ffn.layers.0.0.bias, backbone.stages.2.blocks.17.ffn.layers.1.weight, backbone.stages.2.blocks.17.ffn.layers.1.bias, backbone.stages.2.downsample.norm.weight, backbone.stages.2.downsample.norm.bias, backbone.stages.2.downsample.reduction.weight, backbone.stages.3.blocks.0.norm1.weight, backbone.stages.3.blocks.0.norm1.bias, backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table, backbone.stages.3.blocks.0.attn.w_msa.relative_position_index, backbone.stages.3.blocks.0.attn.w_msa.qkv.weight, backbone.stages.3.blocks.0.attn.w_msa.qkv.bias, backbone.stages.3.blocks.0.attn.w_msa.proj.weight, backbone.stages.3.blocks.0.attn.w_msa.proj.bias, backbone.stages.3.blocks.0.norm2.weight, backbone.stages.3.blocks.0.norm2.bias, backbone.stages.3.blocks.0.ffn.layers.0.0.weight, backbone.stages.3.blocks.0.ffn.layers.0.0.bias, backbone.stages.3.blocks.0.ffn.layers.1.weight, backbone.stages.3.blocks.0.ffn.layers.1.bias, backbone.stages.3.blocks.1.norm1.weight, backbone.stages.3.blocks.1.norm1.bias, backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table, backbone.stages.3.blocks.1.attn.w_msa.relative_position_index, backbone.stages.3.blocks.1.attn.w_msa.qkv.weight, backbone.stages.3.blocks.1.attn.w_msa.qkv.bias, backbone.stages.3.blocks.1.attn.w_msa.proj.weight, backbone.stages.3.blocks.1.attn.w_msa.proj.bias, backbone.stages.3.blocks.1.norm2.weight, backbone.stages.3.blocks.1.norm2.bias, backbone.stages.3.blocks.1.ffn.layers.0.0.weight, backbone.stages.3.blocks.1.ffn.layers.0.0.bias, backbone.stages.3.blocks.1.ffn.layers.1.weight, backbone.stages.3.blocks.1.ffn.layers.1.bias, backbone.norm0.weight, backbone.norm0.bias, backbone.norm1.weight, backbone.norm1.bias, backbone.norm2.weight, backbone.norm2.bias, backbone.norm3.weight, backbone.norm3.bias\n",
      "\n",
      "missing keys in source state_dict: level_embed, backbone.conv1.weight, backbone.bn1.weight, backbone.bn1.bias, backbone.bn1.running_mean, backbone.bn1.running_var, backbone.layer1.0.conv1.weight, backbone.layer1.0.bn1.weight, backbone.layer1.0.bn1.bias, backbone.layer1.0.bn1.running_mean, backbone.layer1.0.bn1.running_var, backbone.layer1.0.conv2.weight, backbone.layer1.0.bn2.weight, backbone.layer1.0.bn2.bias, backbone.layer1.0.bn2.running_mean, backbone.layer1.0.bn2.running_var, backbone.layer1.0.conv3.weight, backbone.layer1.0.bn3.weight, backbone.layer1.0.bn3.bias, backbone.layer1.0.bn3.running_mean, backbone.layer1.0.bn3.running_var, backbone.layer1.0.downsample.0.weight, backbone.layer1.0.downsample.1.weight, backbone.layer1.0.downsample.1.bias, backbone.layer1.0.downsample.1.running_mean, backbone.layer1.0.downsample.1.running_var, backbone.layer1.1.conv1.weight, backbone.layer1.1.bn1.weight, backbone.layer1.1.bn1.bias, backbone.layer1.1.bn1.running_mean, backbone.layer1.1.bn1.running_var, backbone.layer1.1.conv2.weight, backbone.layer1.1.bn2.weight, backbone.layer1.1.bn2.bias, backbone.layer1.1.bn2.running_mean, backbone.layer1.1.bn2.running_var, backbone.layer1.1.conv3.weight, backbone.layer1.1.bn3.weight, backbone.layer1.1.bn3.bias, backbone.layer1.1.bn3.running_mean, backbone.layer1.1.bn3.running_var, backbone.layer1.2.conv1.weight, backbone.layer1.2.bn1.weight, backbone.layer1.2.bn1.bias, backbone.layer1.2.bn1.running_mean, backbone.layer1.2.bn1.running_var, backbone.layer1.2.conv2.weight, backbone.layer1.2.bn2.weight, backbone.layer1.2.bn2.bias, backbone.layer1.2.bn2.running_mean, backbone.layer1.2.bn2.running_var, backbone.layer1.2.conv3.weight, backbone.layer1.2.bn3.weight, backbone.layer1.2.bn3.bias, backbone.layer1.2.bn3.running_mean, backbone.layer1.2.bn3.running_var, backbone.layer2.0.conv1.weight, backbone.layer2.0.bn1.weight, backbone.layer2.0.bn1.bias, backbone.layer2.0.bn1.running_mean, backbone.layer2.0.bn1.running_var, backbone.layer2.0.conv2.weight, backbone.layer2.0.bn2.weight, backbone.layer2.0.bn2.bias, backbone.layer2.0.bn2.running_mean, backbone.layer2.0.bn2.running_var, backbone.layer2.0.conv3.weight, backbone.layer2.0.bn3.weight, backbone.layer2.0.bn3.bias, backbone.layer2.0.bn3.running_mean, backbone.layer2.0.bn3.running_var, backbone.layer2.0.downsample.0.weight, backbone.layer2.0.downsample.1.weight, backbone.layer2.0.downsample.1.bias, backbone.layer2.0.downsample.1.running_mean, backbone.layer2.0.downsample.1.running_var, backbone.layer2.1.conv1.weight, backbone.layer2.1.bn1.weight, backbone.layer2.1.bn1.bias, backbone.layer2.1.bn1.running_mean, backbone.layer2.1.bn1.running_var, backbone.layer2.1.conv2.weight, backbone.layer2.1.bn2.weight, backbone.layer2.1.bn2.bias, backbone.layer2.1.bn2.running_mean, backbone.layer2.1.bn2.running_var, backbone.layer2.1.conv3.weight, backbone.layer2.1.bn3.weight, backbone.layer2.1.bn3.bias, backbone.layer2.1.bn3.running_mean, backbone.layer2.1.bn3.running_var, backbone.layer2.2.conv1.weight, backbone.layer2.2.bn1.weight, backbone.layer2.2.bn1.bias, backbone.layer2.2.bn1.running_mean, backbone.layer2.2.bn1.running_var, backbone.layer2.2.conv2.weight, backbone.layer2.2.bn2.weight, backbone.layer2.2.bn2.bias, backbone.layer2.2.bn2.running_mean, backbone.layer2.2.bn2.running_var, backbone.layer2.2.conv3.weight, backbone.layer2.2.bn3.weight, backbone.layer2.2.bn3.bias, backbone.layer2.2.bn3.running_mean, backbone.layer2.2.bn3.running_var, backbone.layer2.3.conv1.weight, backbone.layer2.3.bn1.weight, backbone.layer2.3.bn1.bias, backbone.layer2.3.bn1.running_mean, backbone.layer2.3.bn1.running_var, backbone.layer2.3.conv2.weight, backbone.layer2.3.bn2.weight, backbone.layer2.3.bn2.bias, backbone.layer2.3.bn2.running_mean, backbone.layer2.3.bn2.running_var, backbone.layer2.3.conv3.weight, backbone.layer2.3.bn3.weight, backbone.layer2.3.bn3.bias, backbone.layer2.3.bn3.running_mean, backbone.layer2.3.bn3.running_var, backbone.layer3.0.conv1.weight, backbone.layer3.0.bn1.weight, backbone.layer3.0.bn1.bias, backbone.layer3.0.bn1.running_mean, backbone.layer3.0.bn1.running_var, backbone.layer3.0.conv2.weight, backbone.layer3.0.bn2.weight, backbone.layer3.0.bn2.bias, backbone.layer3.0.bn2.running_mean, backbone.layer3.0.bn2.running_var, backbone.layer3.0.conv3.weight, backbone.layer3.0.bn3.weight, backbone.layer3.0.bn3.bias, backbone.layer3.0.bn3.running_mean, backbone.layer3.0.bn3.running_var, backbone.layer3.0.downsample.0.weight, backbone.layer3.0.downsample.1.weight, backbone.layer3.0.downsample.1.bias, backbone.layer3.0.downsample.1.running_mean, backbone.layer3.0.downsample.1.running_var, backbone.layer3.1.conv1.weight, backbone.layer3.1.bn1.weight, backbone.layer3.1.bn1.bias, backbone.layer3.1.bn1.running_mean, backbone.layer3.1.bn1.running_var, backbone.layer3.1.conv2.weight, backbone.layer3.1.bn2.weight, backbone.layer3.1.bn2.bias, backbone.layer3.1.bn2.running_mean, backbone.layer3.1.bn2.running_var, backbone.layer3.1.conv3.weight, backbone.layer3.1.bn3.weight, backbone.layer3.1.bn3.bias, backbone.layer3.1.bn3.running_mean, backbone.layer3.1.bn3.running_var, backbone.layer3.2.conv1.weight, backbone.layer3.2.bn1.weight, backbone.layer3.2.bn1.bias, backbone.layer3.2.bn1.running_mean, backbone.layer3.2.bn1.running_var, backbone.layer3.2.conv2.weight, backbone.layer3.2.bn2.weight, backbone.layer3.2.bn2.bias, backbone.layer3.2.bn2.running_mean, backbone.layer3.2.bn2.running_var, backbone.layer3.2.conv3.weight, backbone.layer3.2.bn3.weight, backbone.layer3.2.bn3.bias, backbone.layer3.2.bn3.running_mean, backbone.layer3.2.bn3.running_var, backbone.layer3.3.conv1.weight, backbone.layer3.3.bn1.weight, backbone.layer3.3.bn1.bias, backbone.layer3.3.bn1.running_mean, backbone.layer3.3.bn1.running_var, backbone.layer3.3.conv2.weight, backbone.layer3.3.bn2.weight, backbone.layer3.3.bn2.bias, backbone.layer3.3.bn2.running_mean, backbone.layer3.3.bn2.running_var, backbone.layer3.3.conv3.weight, backbone.layer3.3.bn3.weight, backbone.layer3.3.bn3.bias, backbone.layer3.3.bn3.running_mean, backbone.layer3.3.bn3.running_var, backbone.layer3.4.conv1.weight, backbone.layer3.4.bn1.weight, backbone.layer3.4.bn1.bias, backbone.layer3.4.bn1.running_mean, backbone.layer3.4.bn1.running_var, backbone.layer3.4.conv2.weight, backbone.layer3.4.bn2.weight, backbone.layer3.4.bn2.bias, backbone.layer3.4.bn2.running_mean, backbone.layer3.4.bn2.running_var, backbone.layer3.4.conv3.weight, backbone.layer3.4.bn3.weight, backbone.layer3.4.bn3.bias, backbone.layer3.4.bn3.running_mean, backbone.layer3.4.bn3.running_var, backbone.layer3.5.conv1.weight, backbone.layer3.5.bn1.weight, backbone.layer3.5.bn1.bias, backbone.layer3.5.bn1.running_mean, backbone.layer3.5.bn1.running_var, backbone.layer3.5.conv2.weight, backbone.layer3.5.bn2.weight, backbone.layer3.5.bn2.bias, backbone.layer3.5.bn2.running_mean, backbone.layer3.5.bn2.running_var, backbone.layer3.5.conv3.weight, backbone.layer3.5.bn3.weight, backbone.layer3.5.bn3.bias, backbone.layer3.5.bn3.running_mean, backbone.layer3.5.bn3.running_var, backbone.layer4.0.conv1.weight, backbone.layer4.0.bn1.weight, backbone.layer4.0.bn1.bias, backbone.layer4.0.bn1.running_mean, backbone.layer4.0.bn1.running_var, backbone.layer4.0.conv2.weight, backbone.layer4.0.bn2.weight, backbone.layer4.0.bn2.bias, backbone.layer4.0.bn2.running_mean, backbone.layer4.0.bn2.running_var, backbone.layer4.0.conv3.weight, backbone.layer4.0.bn3.weight, backbone.layer4.0.bn3.bias, backbone.layer4.0.bn3.running_mean, backbone.layer4.0.bn3.running_var, backbone.layer4.0.downsample.0.weight, backbone.layer4.0.downsample.1.weight, backbone.layer4.0.downsample.1.bias, backbone.layer4.0.downsample.1.running_mean, backbone.layer4.0.downsample.1.running_var, backbone.layer4.1.conv1.weight, backbone.layer4.1.bn1.weight, backbone.layer4.1.bn1.bias, backbone.layer4.1.bn1.running_mean, backbone.layer4.1.bn1.running_var, backbone.layer4.1.conv2.weight, backbone.layer4.1.bn2.weight, backbone.layer4.1.bn2.bias, backbone.layer4.1.bn2.running_mean, backbone.layer4.1.bn2.running_var, backbone.layer4.1.conv3.weight, backbone.layer4.1.bn3.weight, backbone.layer4.1.bn3.bias, backbone.layer4.1.bn3.running_mean, backbone.layer4.1.bn3.running_var, backbone.layer4.2.conv1.weight, backbone.layer4.2.bn1.weight, backbone.layer4.2.bn1.bias, backbone.layer4.2.bn1.running_mean, backbone.layer4.2.bn1.running_var, backbone.layer4.2.conv2.weight, backbone.layer4.2.bn2.weight, backbone.layer4.2.bn2.bias, backbone.layer4.2.bn2.running_mean, backbone.layer4.2.bn2.running_var, backbone.layer4.2.conv3.weight, backbone.layer4.2.bn3.weight, backbone.layer4.2.bn3.bias, backbone.layer4.2.bn3.running_mean, backbone.layer4.2.bn3.running_var, neck.convs.0.conv.weight, neck.convs.0.gn.weight, neck.convs.0.gn.bias, neck.convs.1.conv.weight, neck.convs.1.gn.weight, neck.convs.1.gn.bias, neck.convs.2.conv.weight, neck.convs.2.gn.weight, neck.convs.2.gn.bias, neck.extra_convs.0.conv.weight, neck.extra_convs.0.gn.weight, neck.extra_convs.0.gn.bias, bbox_head.cls_branches.0.weight, bbox_head.cls_branches.0.bias, bbox_head.cls_branches.1.weight, bbox_head.cls_branches.1.bias, bbox_head.cls_branches.2.weight, bbox_head.cls_branches.2.bias, bbox_head.cls_branches.3.weight, bbox_head.cls_branches.3.bias, bbox_head.cls_branches.4.weight, bbox_head.cls_branches.4.bias, bbox_head.cls_branches.5.weight, bbox_head.cls_branches.5.bias, bbox_head.cls_branches.6.weight, bbox_head.cls_branches.6.bias, bbox_head.reg_branches.0.0.weight, bbox_head.reg_branches.0.0.bias, bbox_head.reg_branches.0.2.weight, bbox_head.reg_branches.0.2.bias, bbox_head.reg_branches.0.4.weight, bbox_head.reg_branches.0.4.bias, bbox_head.reg_branches.1.0.weight, bbox_head.reg_branches.1.0.bias, bbox_head.reg_branches.1.2.weight, bbox_head.reg_branches.1.2.bias, bbox_head.reg_branches.1.4.weight, bbox_head.reg_branches.1.4.bias, bbox_head.reg_branches.2.0.weight, bbox_head.reg_branches.2.0.bias, bbox_head.reg_branches.2.2.weight, bbox_head.reg_branches.2.2.bias, bbox_head.reg_branches.2.4.weight, bbox_head.reg_branches.2.4.bias, bbox_head.reg_branches.3.0.weight, bbox_head.reg_branches.3.0.bias, bbox_head.reg_branches.3.2.weight, bbox_head.reg_branches.3.2.bias, bbox_head.reg_branches.3.4.weight, bbox_head.reg_branches.3.4.bias, bbox_head.reg_branches.4.0.weight, bbox_head.reg_branches.4.0.bias, bbox_head.reg_branches.4.2.weight, bbox_head.reg_branches.4.2.bias, bbox_head.reg_branches.4.4.weight, bbox_head.reg_branches.4.4.bias, bbox_head.reg_branches.5.0.weight, bbox_head.reg_branches.5.0.bias, bbox_head.reg_branches.5.2.weight, bbox_head.reg_branches.5.2.bias, bbox_head.reg_branches.5.4.weight, bbox_head.reg_branches.5.4.bias, bbox_head.reg_branches.6.0.weight, bbox_head.reg_branches.6.0.bias, bbox_head.reg_branches.6.2.weight, bbox_head.reg_branches.6.2.bias, bbox_head.reg_branches.6.4.weight, bbox_head.reg_branches.6.4.bias, encoder.layers.0.self_attn.sampling_offsets.weight, encoder.layers.0.self_attn.sampling_offsets.bias, encoder.layers.0.self_attn.attention_weights.weight, encoder.layers.0.self_attn.attention_weights.bias, encoder.layers.0.self_attn.value_proj.weight, encoder.layers.0.self_attn.value_proj.bias, encoder.layers.0.self_attn.output_proj.weight, encoder.layers.0.self_attn.output_proj.bias, encoder.layers.0.ffn.layers.0.0.weight, encoder.layers.0.ffn.layers.0.0.bias, encoder.layers.0.ffn.layers.1.weight, encoder.layers.0.ffn.layers.1.bias, encoder.layers.0.norms.0.weight, encoder.layers.0.norms.0.bias, encoder.layers.0.norms.1.weight, encoder.layers.0.norms.1.bias, encoder.layers.1.self_attn.sampling_offsets.weight, encoder.layers.1.self_attn.sampling_offsets.bias, encoder.layers.1.self_attn.attention_weights.weight, encoder.layers.1.self_attn.attention_weights.bias, encoder.layers.1.self_attn.value_proj.weight, encoder.layers.1.self_attn.value_proj.bias, encoder.layers.1.self_attn.output_proj.weight, encoder.layers.1.self_attn.output_proj.bias, encoder.layers.1.ffn.layers.0.0.weight, encoder.layers.1.ffn.layers.0.0.bias, encoder.layers.1.ffn.layers.1.weight, encoder.layers.1.ffn.layers.1.bias, encoder.layers.1.norms.0.weight, encoder.layers.1.norms.0.bias, encoder.layers.1.norms.1.weight, encoder.layers.1.norms.1.bias, encoder.layers.2.self_attn.sampling_offsets.weight, encoder.layers.2.self_attn.sampling_offsets.bias, encoder.layers.2.self_attn.attention_weights.weight, encoder.layers.2.self_attn.attention_weights.bias, encoder.layers.2.self_attn.value_proj.weight, encoder.layers.2.self_attn.value_proj.bias, encoder.layers.2.self_attn.output_proj.weight, encoder.layers.2.self_attn.output_proj.bias, encoder.layers.2.ffn.layers.0.0.weight, encoder.layers.2.ffn.layers.0.0.bias, encoder.layers.2.ffn.layers.1.weight, encoder.layers.2.ffn.layers.1.bias, encoder.layers.2.norms.0.weight, encoder.layers.2.norms.0.bias, encoder.layers.2.norms.1.weight, encoder.layers.2.norms.1.bias, encoder.layers.3.self_attn.sampling_offsets.weight, encoder.layers.3.self_attn.sampling_offsets.bias, encoder.layers.3.self_attn.attention_weights.weight, encoder.layers.3.self_attn.attention_weights.bias, encoder.layers.3.self_attn.value_proj.weight, encoder.layers.3.self_attn.value_proj.bias, encoder.layers.3.self_attn.output_proj.weight, encoder.layers.3.self_attn.output_proj.bias, encoder.layers.3.ffn.layers.0.0.weight, encoder.layers.3.ffn.layers.0.0.bias, encoder.layers.3.ffn.layers.1.weight, encoder.layers.3.ffn.layers.1.bias, encoder.layers.3.norms.0.weight, encoder.layers.3.norms.0.bias, encoder.layers.3.norms.1.weight, encoder.layers.3.norms.1.bias, encoder.layers.4.self_attn.sampling_offsets.weight, encoder.layers.4.self_attn.sampling_offsets.bias, encoder.layers.4.self_attn.attention_weights.weight, encoder.layers.4.self_attn.attention_weights.bias, encoder.layers.4.self_attn.value_proj.weight, encoder.layers.4.self_attn.value_proj.bias, encoder.layers.4.self_attn.output_proj.weight, encoder.layers.4.self_attn.output_proj.bias, encoder.layers.4.ffn.layers.0.0.weight, encoder.layers.4.ffn.layers.0.0.bias, encoder.layers.4.ffn.layers.1.weight, encoder.layers.4.ffn.layers.1.bias, encoder.layers.4.norms.0.weight, encoder.layers.4.norms.0.bias, encoder.layers.4.norms.1.weight, encoder.layers.4.norms.1.bias, encoder.layers.5.self_attn.sampling_offsets.weight, encoder.layers.5.self_attn.sampling_offsets.bias, encoder.layers.5.self_attn.attention_weights.weight, encoder.layers.5.self_attn.attention_weights.bias, encoder.layers.5.self_attn.value_proj.weight, encoder.layers.5.self_attn.value_proj.bias, encoder.layers.5.self_attn.output_proj.weight, encoder.layers.5.self_attn.output_proj.bias, encoder.layers.5.ffn.layers.0.0.weight, encoder.layers.5.ffn.layers.0.0.bias, encoder.layers.5.ffn.layers.1.weight, encoder.layers.5.ffn.layers.1.bias, encoder.layers.5.norms.0.weight, encoder.layers.5.norms.0.bias, encoder.layers.5.norms.1.weight, encoder.layers.5.norms.1.bias, decoder.layers.0.self_attn.attn.in_proj_weight, decoder.layers.0.self_attn.attn.in_proj_bias, decoder.layers.0.self_attn.attn.out_proj.weight, decoder.layers.0.self_attn.attn.out_proj.bias, decoder.layers.0.cross_attn.sampling_offsets.weight, decoder.layers.0.cross_attn.sampling_offsets.bias, decoder.layers.0.cross_attn.attention_weights.weight, decoder.layers.0.cross_attn.attention_weights.bias, decoder.layers.0.cross_attn.value_proj.weight, decoder.layers.0.cross_attn.value_proj.bias, decoder.layers.0.cross_attn.output_proj.weight, decoder.layers.0.cross_attn.output_proj.bias, decoder.layers.0.ffn.layers.0.0.weight, decoder.layers.0.ffn.layers.0.0.bias, decoder.layers.0.ffn.layers.1.weight, decoder.layers.0.ffn.layers.1.bias, decoder.layers.0.norms.0.weight, decoder.layers.0.norms.0.bias, decoder.layers.0.norms.1.weight, decoder.layers.0.norms.1.bias, decoder.layers.0.norms.2.weight, decoder.layers.0.norms.2.bias, decoder.layers.1.self_attn.attn.in_proj_weight, decoder.layers.1.self_attn.attn.in_proj_bias, decoder.layers.1.self_attn.attn.out_proj.weight, decoder.layers.1.self_attn.attn.out_proj.bias, decoder.layers.1.cross_attn.sampling_offsets.weight, decoder.layers.1.cross_attn.sampling_offsets.bias, decoder.layers.1.cross_attn.attention_weights.weight, decoder.layers.1.cross_attn.attention_weights.bias, decoder.layers.1.cross_attn.value_proj.weight, decoder.layers.1.cross_attn.value_proj.bias, decoder.layers.1.cross_attn.output_proj.weight, decoder.layers.1.cross_attn.output_proj.bias, decoder.layers.1.ffn.layers.0.0.weight, decoder.layers.1.ffn.layers.0.0.bias, decoder.layers.1.ffn.layers.1.weight, decoder.layers.1.ffn.layers.1.bias, decoder.layers.1.norms.0.weight, decoder.layers.1.norms.0.bias, decoder.layers.1.norms.1.weight, decoder.layers.1.norms.1.bias, decoder.layers.1.norms.2.weight, decoder.layers.1.norms.2.bias, decoder.layers.2.self_attn.attn.in_proj_weight, decoder.layers.2.self_attn.attn.in_proj_bias, decoder.layers.2.self_attn.attn.out_proj.weight, decoder.layers.2.self_attn.attn.out_proj.bias, decoder.layers.2.cross_attn.sampling_offsets.weight, decoder.layers.2.cross_attn.sampling_offsets.bias, decoder.layers.2.cross_attn.attention_weights.weight, decoder.layers.2.cross_attn.attention_weights.bias, decoder.layers.2.cross_attn.value_proj.weight, decoder.layers.2.cross_attn.value_proj.bias, decoder.layers.2.cross_attn.output_proj.weight, decoder.layers.2.cross_attn.output_proj.bias, decoder.layers.2.ffn.layers.0.0.weight, decoder.layers.2.ffn.layers.0.0.bias, decoder.layers.2.ffn.layers.1.weight, decoder.layers.2.ffn.layers.1.bias, decoder.layers.2.norms.0.weight, decoder.layers.2.norms.0.bias, decoder.layers.2.norms.1.weight, decoder.layers.2.norms.1.bias, decoder.layers.2.norms.2.weight, decoder.layers.2.norms.2.bias, decoder.layers.3.self_attn.attn.in_proj_weight, decoder.layers.3.self_attn.attn.in_proj_bias, decoder.layers.3.self_attn.attn.out_proj.weight, decoder.layers.3.self_attn.attn.out_proj.bias, decoder.layers.3.cross_attn.sampling_offsets.weight, decoder.layers.3.cross_attn.sampling_offsets.bias, decoder.layers.3.cross_attn.attention_weights.weight, decoder.layers.3.cross_attn.attention_weights.bias, decoder.layers.3.cross_attn.value_proj.weight, decoder.layers.3.cross_attn.value_proj.bias, decoder.layers.3.cross_attn.output_proj.weight, decoder.layers.3.cross_attn.output_proj.bias, decoder.layers.3.ffn.layers.0.0.weight, decoder.layers.3.ffn.layers.0.0.bias, decoder.layers.3.ffn.layers.1.weight, decoder.layers.3.ffn.layers.1.bias, decoder.layers.3.norms.0.weight, decoder.layers.3.norms.0.bias, decoder.layers.3.norms.1.weight, decoder.layers.3.norms.1.bias, decoder.layers.3.norms.2.weight, decoder.layers.3.norms.2.bias, decoder.layers.4.self_attn.attn.in_proj_weight, decoder.layers.4.self_attn.attn.in_proj_bias, decoder.layers.4.self_attn.attn.out_proj.weight, decoder.layers.4.self_attn.attn.out_proj.bias, decoder.layers.4.cross_attn.sampling_offsets.weight, decoder.layers.4.cross_attn.sampling_offsets.bias, decoder.layers.4.cross_attn.attention_weights.weight, decoder.layers.4.cross_attn.attention_weights.bias, decoder.layers.4.cross_attn.value_proj.weight, decoder.layers.4.cross_attn.value_proj.bias, decoder.layers.4.cross_attn.output_proj.weight, decoder.layers.4.cross_attn.output_proj.bias, decoder.layers.4.ffn.layers.0.0.weight, decoder.layers.4.ffn.layers.0.0.bias, decoder.layers.4.ffn.layers.1.weight, decoder.layers.4.ffn.layers.1.bias, decoder.layers.4.norms.0.weight, decoder.layers.4.norms.0.bias, decoder.layers.4.norms.1.weight, decoder.layers.4.norms.1.bias, decoder.layers.4.norms.2.weight, decoder.layers.4.norms.2.bias, decoder.layers.5.self_attn.attn.in_proj_weight, decoder.layers.5.self_attn.attn.in_proj_bias, decoder.layers.5.self_attn.attn.out_proj.weight, decoder.layers.5.self_attn.attn.out_proj.bias, decoder.layers.5.cross_attn.sampling_offsets.weight, decoder.layers.5.cross_attn.sampling_offsets.bias, decoder.layers.5.cross_attn.attention_weights.weight, decoder.layers.5.cross_attn.attention_weights.bias, decoder.layers.5.cross_attn.value_proj.weight, decoder.layers.5.cross_attn.value_proj.bias, decoder.layers.5.cross_attn.output_proj.weight, decoder.layers.5.cross_attn.output_proj.bias, decoder.layers.5.ffn.layers.0.0.weight, decoder.layers.5.ffn.layers.0.0.bias, decoder.layers.5.ffn.layers.1.weight, decoder.layers.5.ffn.layers.1.bias, decoder.layers.5.norms.0.weight, decoder.layers.5.norms.0.bias, decoder.layers.5.norms.1.weight, decoder.layers.5.norms.1.bias, decoder.layers.5.norms.2.weight, decoder.layers.5.norms.2.bias, decoder.ref_point_head.layers.0.weight, decoder.ref_point_head.layers.0.bias, decoder.ref_point_head.layers.1.weight, decoder.ref_point_head.layers.1.bias, decoder.norm.weight, decoder.norm.bias, query_embedding.weight, memory_trans_fc.weight, memory_trans_fc.bias, memory_trans_norm.weight, memory_trans_norm.bias, dn_query_generator.label_embedding.weight\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "#import pydensecrf.densecrf as dcrf\n",
    "\n",
    "from mmdet.apis import init_detector, inference_detector\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "\n",
    "config_file = r\"C:\\Users\\philmarq\\source\\repos\\MMWrapperRepo\\firstapitest\\20230804_162325\\vis_data\\config.py\"\n",
    "checkpoint_file = r\"C:\\Users\\philmarq\\source\\repos\\MMWrapperRepo\\firstapitest\\best_coco_bbox_mAP_epoch_25.pth\"\n",
    "\n",
    "device = 'cuda:0'\n",
    "\n",
    "model = init_detector(config_file, checkpoint_file, device=device)\n",
    "\n",
    "# Load image\n",
    "\n",
    "\n",
    "colors = [(255,0,0), (125,0,0), (0,255,0), (50, 255,0), (0,25,255), (0, 125, 0)]\n",
    "root = r\"C:\\HSA\\HSA-Data\\projects\\d55090aa-a315-4ae3-8242-b50e13e355f6\\dataset\\train2017\"\n",
    "imgs = []\n",
    "for file in os.listdir(root):\n",
    "    img = os.path.join(root, file)\n",
    "    imgs.append(img)\n",
    "    continue\n",
    "    result = inference_detector(model, img)\n",
    "    \n",
    "    \n",
    "\n",
    "    color = (255,0,0)\n",
    "    image = cv2.imread(img)\n",
    "    orig = image.copy()\n",
    "\n",
    "    #image[image>0] = 0\n",
    "    #masks = result.pred_instances.masks.cpu().numpy()\n",
    "    scores = result.pred_instances.scores.cpu().numpy()\n",
    "    labels = result.pred_instances.labels.cpu().numpy()\n",
    "    bboxes = result.pred_instances.bboxes.cpu().numpy()\n",
    "    thresh = 0.35\n",
    "    \n",
    "    for  score,label, bbox in zip(scores,  labels, bboxes):\n",
    "        if score > thresh:\n",
    "            color = colors[label]\n",
    "            x1, y1, x2, y2 = bbox.astype(np.int32)\n",
    "            cv2.rectangle(image, (x1, y1), (x2, y2), color, 1)\n",
    "    \n",
    "    cv2.imwrite(os.path.join(\"outputall\", file), image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273a1ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "from mmseg.apis import init_model, inference_model\n",
    "from mmseg.apis.inference import _preprare_data\n",
    "\n",
    "config_path = r\"C:\\Users\\philmarq\\source\\repos\\MMWrapperRepo\\segmentationtest\\20230807_175346\\vis_data\\config.py\"\n",
    "checkpoint_path = r\"C:\\Users\\philmarq\\source\\repos\\MMWrapperRepo\\segmentationtest\\best_mIoU_epoch_39.pth\"\n",
    "model = init_model(config_path, checkpoint_path)\n",
    "\n",
    "import torch\n",
    "import cv2\n",
    "base = r\"C:\\HSA\\HSA-Data\\projects\\0c5220fa-7e4a-40a5-a7e5-7ac6eba0f34b\\dataset\\valid\\images\"\n",
    "labels = base.replace(\"images\", \"labels\")\n",
    "for file in os.listdir(base):\n",
    "    result = inference_model(model, os.path.join(base, file))\n",
    "    label = cv2.imread(os.path.join(labels, file), 0)\n",
    "    logits =  result.seg_logits.data\n",
    "    \n",
    "    logits = torch.argmax(logits, dim=0).unsqueeze(0)\n",
    "    cv2.imwrite(os.path.join(\"outputall\", file), (result.pred_sem_seg.data.permute(1,2,0).cpu().numpy() + 0) * 50.)\n",
    "    cv2.imwrite(os.path.join(\"outputall\", \"orig_\" + file), label * 50.)\n",
    "    #cv2.imwrite(os.path.join(\"output\", file), logits.permute(1,2,0).cpu().numpy() * 50.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53291be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\philmarq\\miniconda3\\envs\\mmtest\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: C:\\Users\\philmarq\\source\\repos\\MMWrapperRepo\\segmentationtest\\best_mIoU_epoch_67.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\philmarq\\miniconda3\\envs\\mmtest\\lib\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3484.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "from mmseg.apis import init_model as init_model_mmseg\n",
    "from mmseg.apis import  inference_model as inference_model_mmesg\n",
    "from mmseg.apis.inference import _preprare_data\n",
    "\n",
    "config_path = r\"C:\\Users\\philmarq\\source\\repos\\MMWrapperRepo\\segmentationtest\\20230805_125344\\vis_data\\config.py\"\n",
    "checkpoint_path = r\"C:\\Users\\philmarq\\source\\repos\\MMWrapperRepo\\segmentationtest\\best_mIoU_epoch_67.pth\"\n",
    "model = init_model_mmseg(config_path, checkpoint_path)\n",
    "import torch\n",
    "import cv2\n",
    "base = r\"C:/HSA/HSA-Data/projects/035c4d1b-ddad-4bb9-834b-7f2d2658655d/dataset\\valid\\images\"\n",
    "label_base = r\"C:/HSA/HSA-Data/projects/035c4d1b-ddad-4bb9-834b-7f2d2658655d/dataset\\valid\\labels\"\n",
    "output_dir = \"outputall\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for file in os.listdir(base):\n",
    "    image_path = os.path.join(base, file)\n",
    "    label_path = os.path.join(label_base, file)\n",
    "\n",
    "    result = inference_model_mmesg(model, image_path)\n",
    "    logits = result.seg_logits.data\n",
    "    logits = torch.argmax(logits, dim=0).unsqueeze(0)\n",
    "\n",
    "    # Load the ground truth labels\n",
    "    label = cv2.imread(label_path, cv2.IMREAD_GRAYSCALE) * 50.\n",
    "\n",
    "    # Combine prediction and label side by side\n",
    "    combined_img = cv2.hconcat([(result.pred_sem_seg.data.permute(1, 2, 0).cpu().numpy() + 0) * 50., label])\n",
    "\n",
    "    # Save the combined image\n",
    "    cv2.imwrite(os.path.join(output_dir, file), combined_img)\n",
    "    cv2.imwrite(os.path.join(output_dir, \"orig_\" + file), cv2.imread(image_path))\n",
    "    # Save the prediction only\n",
    "    #cv2.imwrite(os.path.join(output_dir, \"prediction_\" + file), (result.pred_sem_seg.data.permute(1, 2, 0).cpu().numpy() + 0) * 50.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401a6376",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pycocotools\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools import mask as mask_utils\n",
    "def encode_rle(mask):\n",
    "    rle = mask_utils.encode(np.asfortranarray(mask))\n",
    "    return {\n",
    "        \"counts\": rle[\"counts\"].decode(),  # Convert the bytes to a string\n",
    "        \"size\": list(rle[\"size\"])\n",
    "    }\n",
    "\n",
    "def create_coco_dict(file):\n",
    "    '''\n",
    "    Creates coco dataset\n",
    "    '''\n",
    "    files = {}\n",
    "    files['info'] = {\"year\": 2222, \"version\": \"1.0\", \"description\": \"Object detection\", \"date_created\": \"2222\"}\n",
    "    files['licenses'] = [{'id': 1,\n",
    "      'name': 'GNU General Public License v3.0',\n",
    "      'url': 'https://github.com/zhiqwang/yolov5-rt-stack/blob/master/LICENSE'}]\n",
    "    files[\"type\"] = \"instances\"\n",
    "    files['categories'] = []\n",
    "    files[\"annotations\"] = []\n",
    "    files['images'] = []\n",
    "    files['categories'].append({'id': 0, 'name': \"0\", 'supercategory': \"0\"})\n",
    "    all_annos = 0                    \n",
    "    im = cv2.imread(file, 0)\n",
    "    empty = np.zeros_like(im)\n",
    "    files['images'].append({'date_captured': '2021',\n",
    "                              'file_name': file,\n",
    "                              'id': 0,\n",
    "                              'height': im.shape[0],\n",
    "                              'width': im.shape[1]})\n",
    "                      \n",
    "    tmp = im.copy()\n",
    "    #get contours of image\n",
    "    contours,hierarchy = cv2.findContours(tmp, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    #black images to draw the contours on\n",
    "    blank = np.zeros_like(tmp)\n",
    "\n",
    "    for cnt, cont in enumerate(contours):\n",
    "        segmentation = []\n",
    "        xmin, ymin, width, height = cv2.boundingRect(cont) #bounding box\n",
    "        if width * height < 3:\n",
    "            continue\n",
    "        image_height = im.shape[0]\n",
    "        image_width = im.shape[1]\n",
    "        \n",
    "        #draw contour for verification\n",
    "        rle_mask = encode_rle(tmp.astype(np.uint8))\n",
    "        files[\"annotations\"].append({\n",
    "            'segmentation': rle_mask,\n",
    "            'area': width * height,\n",
    "            'image_id': 0,\n",
    "            'iscrowd': 0,\n",
    "            'bbox': [xmin, ymin, width, height],\n",
    "            \"category_id\": 0,\n",
    "            \"id\": all_annos\n",
    "        })\n",
    "        all_annos += 1\n",
    "        cv2.drawContours(empty, [cont], 0, 255, -1)  \n",
    "        cv2.imwrite(\"drawn_contours.png\", empty)\n",
    "    \n",
    "    return files\n",
    "  \n",
    "filename = \"test_image.png\" #TODO: insert your filename here!\n",
    "di = create_coco_dict(filename)\n",
    "with open(\"test.json\", \"w\") as handle:\n",
    "    json.dump(di, handle)\n",
    "\n",
    "coco_annotation = COCO(\"test.json\")\n",
    "ann_ids = coco_annotation.getAnnIds(imgIds=[0], iscrowd=None)\n",
    "anns = coco_annotation.loadAnns(ann_ids)\n",
    "\n",
    "mask = np.zeros(cv2.imread(filename,0).shape)\n",
    "for i in range(len(anns)):\n",
    "    mask += coco_annotation.annToMask(anns[i])\n",
    "cv2.imwrite(\"coco_out.png\", mask * 255.)\n",
    "\n",
    "#assert(np.array_equal(cv2.imread(\"coco_out.png\",0),cv2.imread(\"drawn_contours.png\", 0))) #images are not equal even though they should be(?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897e9521",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
